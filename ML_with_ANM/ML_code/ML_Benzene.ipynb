{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../APDFT')\n",
    "sys.path.append('../Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pyscf import gto, scf, dft, cc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyscf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import basis_set_exchange as bse\n",
    "from FcMole import *\n",
    "import os\n",
    "import ast\n",
    "from IPython.display import display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from AP_class import APDFT_perturbator as AP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "total_energy_data = np.load('../Data/Benzene_BNdoping_PBE0_pcX2_opt.npz', allow_pickle=True)\n",
    "electronic_energy_data = np.load('../Data/Benzene_BNdoping_PBE0_pcX2_electronic_opt.npz', allow_pickle=True)\n",
    "\n",
    "# Unpack the data into numpy arrays\n",
    "charges, coords, elements, total_energy, electronic_energy = total_energy_data['charges'], total_energy_data['coords'], total_energy_data['elements'], total_energy_data['energies'], electronic_energy_data['energies']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 12)\n",
      "(17, 12, 3)\n",
      "(17, 12)\n",
      "(17,)\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "# Understand the dimension of the data\n",
    "\n",
    "print(charges.shape) # (17, 12)\n",
    "print(coords.shape) # (17, 12, 3)\n",
    "print(elements.shape) # (17, 12)\n",
    "print(total_energy.shape) # (17,)\n",
    "print(electronic_energy.shape) #(17,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "      <th>elements</th>\n",
       "      <th>total energy</th>\n",
       "      <th>electronic energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, C, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.034644</td>\n",
       "      <td>-336.906006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, B, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.040119</td>\n",
       "      <td>-336.995987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, C, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.032860</td>\n",
       "      <td>-337.004116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.459886</td>\n",
       "      <td>-340.400298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, C, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.463021</td>\n",
       "      <td>-340.318992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[7, 7, 5, 6, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, C, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-233.453088</td>\n",
       "      <td>-340.193778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[7, 7, 6, 5, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, C, B, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.470031</td>\n",
       "      <td>-340.510269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[7, 5, 7, 6, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, C, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-233.464654</td>\n",
       "      <td>-340.067245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[7, 5, 7, 6, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, C, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.470116</td>\n",
       "      <td>-340.126176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[7, 6, 7, 5, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, N, B, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.469772</td>\n",
       "      <td>-340.325617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[7, 6, 7, 5, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, N, B, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-233.465841</td>\n",
       "      <td>-340.168325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[5, 7, 5, 6, 7, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[B, N, B, C, N, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.465899</td>\n",
       "      <td>-340.122083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[7, 6, 6, 7, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, C, N, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-233.468466</td>\n",
       "      <td>-340.209091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 7, 6, 5, 7, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[B, N, C, B, N, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.467910</td>\n",
       "      <td>-340.108576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[7, 7, 7, 5, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, N, B, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-236.886711</td>\n",
       "      <td>-343.827059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[7, 7, 5, 7, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, N, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-236.882851</td>\n",
       "      <td>-343.423752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[7, 5, 7, 5, 7, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, B, N, B, H, H, H, H, H, H]</td>\n",
       "      <td>-236.821051</td>\n",
       "      <td>-343.085881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 charges   \n",
       "0   [7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]  \\\n",
       "1   [7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "2   [7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "3   [7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "4   [7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "5   [7, 7, 5, 6, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "6   [7, 7, 6, 5, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "7   [7, 5, 7, 6, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "8   [7, 5, 7, 6, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "9   [7, 6, 7, 5, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "10  [7, 6, 7, 5, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "11  [5, 7, 5, 6, 7, 6, 1, 1, 1, 1, 1, 1]   \n",
       "12  [7, 6, 6, 7, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "13  [5, 7, 6, 5, 7, 6, 1, 1, 1, 1, 1, 1]   \n",
       "14  [7, 7, 7, 5, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "15  [7, 7, 5, 7, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "16  [7, 5, 7, 5, 7, 5, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                elements  total energy  electronic energy  \n",
       "0   [N, B, C, C, C, C, H, H, H, H, H, H]   -230.034644        -336.906006  \n",
       "1   [N, C, B, C, C, C, H, H, H, H, H, H]   -230.040119        -336.995987  \n",
       "2   [N, C, C, B, C, C, H, H, H, H, H, H]   -230.032860        -337.004116  \n",
       "3   [N, N, B, B, C, C, H, H, H, H, H, H]   -233.459886        -340.400298  \n",
       "4   [N, N, B, C, B, C, H, H, H, H, H, H]   -233.463021        -340.318992  \n",
       "5   [N, N, B, C, C, B, H, H, H, H, H, H]   -233.453088        -340.193778  \n",
       "6   [N, N, C, B, B, C, H, H, H, H, H, H]   -233.470031        -340.510269  \n",
       "7   [N, B, N, C, C, B, H, H, H, H, H, H]   -233.464654        -340.067245  \n",
       "8   [N, B, N, C, B, C, H, H, H, H, H, H]   -233.470116        -340.126176  \n",
       "9   [N, C, N, B, B, C, H, H, H, H, H, H]   -233.469772        -340.325617  \n",
       "10  [N, C, N, B, C, B, H, H, H, H, H, H]   -233.465841        -340.168325  \n",
       "11  [B, N, B, C, N, C, H, H, H, H, H, H]   -233.465899        -340.122083  \n",
       "12  [N, C, C, N, B, B, H, H, H, H, H, H]   -233.468466        -340.209091  \n",
       "13  [B, N, C, B, N, C, H, H, H, H, H, H]   -233.467910        -340.108576  \n",
       "14  [N, N, N, B, B, B, H, H, H, H, H, H]   -236.886711        -343.827059  \n",
       "15  [N, N, B, N, B, B, H, H, H, H, H, H]   -236.882851        -343.423752  \n",
       "16  [N, B, N, B, N, B, H, H, H, H, H, H]   -236.821051        -343.085881  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating pandas dataframe for the data\n",
    "\n",
    "columns = ['charges', 'elements', 'total energy', 'electronic energy']\n",
    "benzene_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "benzene_data['charges'] = charges.tolist()\n",
    "benzene_data['elements'] = elements.tolist()\n",
    "benzene_data['total energy'] = total_energy.tolist()\n",
    "benzene_data['electronic energy'] = electronic_energy.tolist()\n",
    "display(benzene_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANM Calculation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFT Calculation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the atomic coordinates of benzene molecule (the reference molecule for ANM calculations)\n",
    "\n",
    "benz_atom=\"\"\"\n",
    "C        3.22272669       0.22711285       0.00013582\n",
    "C        5.87141753       0.22698034       0.00094988\n",
    "C        7.19597908       2.52071412      -0.00011471\n",
    "C        5.87164800       4.81458054      -0.00200817\n",
    "C        3.22295713       4.81471307      -0.00280461\n",
    "C        1.89839559       2.52097926      -0.00174231\n",
    "H        2.18773340      -1.56549239       0.00096741\n",
    "H        6.90623079      -1.56572844       0.00241360\n",
    "H        9.26591446       2.52061061       0.00051784\n",
    "H        6.90664130       6.60718579      -0.00284841\n",
    "H        2.18814386       6.60742187      -0.00426425\n",
    "H       -0.17153979       2.52108280      -0.00237226\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the basis used: pcx2\n",
    "\n",
    "basis_pcx2={\"H\":\"pc-2\",'C':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[6])\\\n",
    "           ,'N':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[7])\\\n",
    "           ,'O':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[8])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -229.912170593056\n",
      "Total energy: <bound method energy_tot of RKS object of <class 'pyscf.dft.rks.RKS'>>\n",
      "Electronic energy: <bound method energy_elec of RKS object of <class 'pyscf.dft.rks.RKS'>>\n"
     ]
    }
   ],
   "source": [
    "# create molecule\n",
    "mol_benz=gto.M(atom=benz_atom, basis=basis_pcx2, unit='Angstrom')\n",
    "\n",
    "# run DFT calculation\n",
    "benz_DFT = scf.RKS(mol_benz)\n",
    "benz_DFT.xc = \"PBE0\" # specify the exchange-correlation functional used for DFT\n",
    "benz_DFT.kernel() # run self-consistent field calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total energy: -229.91217059305342\n",
      "Electronic energy: (-336.9833214880193, 181.97988746354838)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total and electronic energy\n",
    "\n",
    "benz_total_energy = benz_DFT.energy_tot()\n",
    "benz_electronic_energy = benz_DFT.energy_elec()\n",
    "\n",
    "print(\"Total energy:\", benz_total_energy)\n",
    "print(\"Electronic energy:\", benz_electronic_energy) #(electronic energy, nuclear repulsion energy)\n",
    "\n",
    "# Total energy: -229.91217059305342\n",
    "# Electronic energy: (-336.9833214880193, 181.97988746354838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyscf.dft.rks.RKS'>\n"
     ]
    }
   ],
   "source": [
    "print(type(benz_DFT))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian and ANM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Hessian\n",
    "\n",
    "def get_hessian(DFT):\n",
    "    \"\"\" \n",
    "    Load the energy hessian matrix of the specified molecule with respect to its nuclear charges\n",
    "    \n",
    "    Args:\n",
    "        DFT (pyscf.dft.rks.RKS object): the DFT RKS object of the molecule in question\n",
    "    \n",
    "    Returns:\n",
    "        H (ndarray): The hessian matrix of the molecule\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.isfile('hessian_PBE0.txt'):\n",
    "        H = np.loadtxt('hessian_PBE0.txt')\n",
    "    else:\n",
    "        C_idxs = [0, 1, 2, 3, 4, 5]\n",
    "        benz_ap=AP(DFT, sites=C_idxs)\n",
    "        H = benz_ap.build_hessian()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.37583818  0.16302604  0.15061107  0.13936407  0.16491505  0.14365052]\n",
      " [ 0.16302604 -3.37583589  0.14365083  0.16491407  0.13936633  0.15060779]\n",
      " [ 0.15061107  0.14365083 -3.40105126  0.14365107  0.1506074   0.19166145]\n",
      " [ 0.13936407  0.16491407  0.14365107 -3.37583742  0.16302608  0.15061038]\n",
      " [ 0.16491505  0.13936633  0.1506074   0.16302608 -3.37583547  0.14365075]\n",
      " [ 0.14365052  0.15060779  0.19166145  0.15061038  0.14365075 -3.40104752]]\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessian\n",
    "\n",
    "H = get_hessian(benz_DFT)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.09259973e-01 -6.06256052e-02  5.00021152e-01  2.87226831e-01\n",
      "   4.99965083e-01  4.96331866e-01]\n",
      " [-4.09260235e-01  6.05875481e-02 -4.99980480e-01  2.87228132e-01\n",
      "   5.00047997e-01 -4.96292987e-01]\n",
      " [-4.06216373e-01  7.01905379e-01 -1.40384008e-05 -5.78764360e-01\n",
      "   1.12864525e-06  8.57257964e-02]\n",
      " [-4.09259834e-01  6.05964964e-02  5.00007350e-01  2.87201859e-01\n",
      "  -4.99964170e-01 -4.96364809e-01]\n",
      " [-4.09260672e-01 -6.05777450e-02 -4.99991015e-01  2.87298223e-01\n",
      "  -5.00022744e-01  4.96268084e-01]\n",
      " [-4.06217532e-01 -7.01883841e-01 -4.20414255e-05 -5.78798226e-01\n",
      "  -2.71244329e-05 -8.56679749e-02]]\n",
      "[[-4.09259973e-01 -4.09260235e-01 -4.06216373e-01 -4.09259834e-01\n",
      "  -4.09260672e-01 -4.06217532e-01]\n",
      " [-6.06256052e-02  6.05875481e-02  7.01905379e-01  6.05964964e-02\n",
      "  -6.05777450e-02 -7.01883841e-01]\n",
      " [ 5.00021152e-01 -4.99980480e-01 -1.40384008e-05  5.00007350e-01\n",
      "  -4.99991015e-01 -4.20414255e-05]\n",
      " [ 2.87226831e-01  2.87228132e-01 -5.78764360e-01  2.87201859e-01\n",
      "   2.87298223e-01 -5.78798226e-01]\n",
      " [ 4.99965083e-01  5.00047997e-01  1.12864526e-06 -4.99964170e-01\n",
      "  -5.00022744e-01 -2.71244329e-05]\n",
      " [ 4.96331866e-01 -4.96292987e-01  8.57257964e-02 -4.96364809e-01\n",
      "   4.96268084e-01 -8.56679749e-02]]\n",
      "[-2.61645906 -3.59391232 -3.56441216 -3.50145981 -3.51709044 -3.51211196]\n"
     ]
    }
   ],
   "source": [
    "# compute the diagnalization matrix (of eigenvectors) Q\n",
    "\n",
    "epsilon, Q = np.linalg.eig(H)\n",
    "Q_inv = np.linalg.inv(Q)\n",
    "print(Q)\n",
    "print(Q_inv)\n",
    "print(epsilon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexi_transformation(arr):\n",
    "    \"\"\" \n",
    "    This function maps cyclic arrays that are rotational or reflectional identical onto the same vector.\n",
    "    The function iterate through all rotaional and reflectional variants of the array,\n",
    "    and select the lexicographically minimum array as the final representation.\n",
    "\n",
    "    Args:\n",
    "        arr (ndarray): a numpy array to be transformed\n",
    "    \n",
    "    Return:\n",
    "        transformed_arr (ndarray): transformed array\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create all possible rotations of the cycle\n",
    "    shift = np.arange(len(arr))\n",
    "\n",
    "    shifted_arrays = []\n",
    "    for s in shift:\n",
    "        shifted = np.roll(arr, shift=s)\n",
    "        shifted_arrays.append(shifted)\n",
    "    \n",
    "    rotations = np.vstack(shifted_arrays)\n",
    "\n",
    "    # Create the corresponding reverse traversal patterns for each rotation\n",
    "    reverse_traversals = np.flip(rotations, axis=1)\n",
    "\n",
    "    # Combine rotations and reverse traversals\n",
    "    all_patterns = np.vstack((rotations, reverse_traversals))\n",
    "\n",
    "    # Find the lexicographically smallest representation (left to right)\n",
    "    sorted_indices = np.lexsort(all_patterns.T[::-1])\n",
    "    min_pattern = all_patterns[sorted_indices[0]]\n",
    "    \n",
    "    # Return the lexicographically smallest pattern as the vector representation\n",
    "    return min_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexi_transformation_2d(arr):\n",
    "    transformed_arr = []\n",
    "    \n",
    "    for row in arr:\n",
    "        transformed_row = lexi_transformation(row)\n",
    "        transformed_arr.append(transformed_row)\n",
    "    \n",
    "    return np.array(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexi_and_opposite_transformation(arr):\n",
    "    \"\"\" \n",
    "    This function maps cyclic arrays that are rotational identical, reflectional identical, \n",
    "    or opposite onto the same vector.\n",
    "    The function iterate through all rotaional, reflectional, and opposite variants of the array,\n",
    "    and select the lexicographically minimum array as the final representation.\n",
    "\n",
    "    Args:\n",
    "        arr (ndarray): a numpy array to be transformed\n",
    "    \n",
    "    Return:\n",
    "        transformed_arr (ndarray): transformed array\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create all possible rotations of the cycle\n",
    "    shift = np.arange(len(arr))\n",
    "\n",
    "    shifted_arrays = []\n",
    "    for s in shift:\n",
    "        shifted = np.roll(arr, shift=s)\n",
    "        shifted_arrays.append(shifted)\n",
    "    \n",
    "    rotations = np.vstack(shifted_arrays)\n",
    "\n",
    "    # Create the corresponding reverse traversal patterns for each rotation\n",
    "    reverse_traversals = np.flip(rotations, axis=1)\n",
    "\n",
    "    # Combine rotations and reverse traversals\n",
    "    all_patterns = np.vstack((rotations, reverse_traversals))\n",
    "    \n",
    "    # Negate existing vectors \n",
    "    all_patterns_neg = -all_patterns\n",
    "\n",
    "    # Combing the negated vectors with the original\n",
    "    all_patterns = np.vstack((all_patterns, all_patterns_neg))\n",
    "\n",
    "    # Find the lexicographically smallest representation (left to right)\n",
    "    sorted_indices = np.lexsort(all_patterns.T[::-1])\n",
    "    min_pattern = all_patterns[sorted_indices[0]]\n",
    "    \n",
    "    # Return the lexicographically smallest pattern as the vector representation\n",
    "    return min_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexi_and_opposite_transformation_2d(arr):\n",
    "    transformed_arr = []\n",
    "    \n",
    "    for row in arr:\n",
    "        transformed_row = lexi_and_opposite_transformation(row)\n",
    "        transformed_arr.append(transformed_row)\n",
    "    \n",
    "    return np.array(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 -1  0  1]\n"
     ]
    }
   ],
   "source": [
    "mylist = np.array([[0, 1, 0, 0, 0, -1], \n",
    "                   [0, 0, 0, -1, 0, 1],\n",
    "                   [1, 0, 0, 0, -1, 0]])\n",
    "\n",
    "index = np.lexsort(mylist.T[::-1])\n",
    "print(mylist[index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1  0  0  1]\n",
      "[-1  0  0 -1  1  1]\n",
      "[-1  0  0  0  1  0]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([1, -1, -1, 1, 0, 0])\n",
    "arr2 = np.array([-1, 1, 1, -1, 0, 0])\n",
    "arr3 = np.array([1, 0, -1, 0, 0, 0])\n",
    "transformed_arr1 = lexi_transformation(arr1)\n",
    "transformed_arr2 = lexi_transformation(arr2)\n",
    "transformed_arr3 = lexi_transformation(arr3)\n",
    "print(transformed_arr1)\n",
    "print(transformed_arr2)\n",
    "print(transformed_arr3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating dx and c ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 6)\n",
      "(17, 6)\n",
      "(17, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "      <th>elements</th>\n",
       "      <th>total energy</th>\n",
       "      <th>electronic energy</th>\n",
       "      <th>sorted_dx</th>\n",
       "      <th>lexi_dx</th>\n",
       "      <th>lexi_opp_dx</th>\n",
       "      <th>sorted_c</th>\n",
       "      <th>lexi_c</th>\n",
       "      <th>lexi_opp_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, C, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.034644</td>\n",
       "      <td>-336.906006</td>\n",
       "      <td>[-1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[-1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[-1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.003042440870520857, -0.6412582352904221, -0...</td>\n",
       "      <td>[0.003042440870520857, -0.6412582352904221, -0...</td>\n",
       "      <td>[0.003042440870520857, -0.6412582352904221, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, B, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.040119</td>\n",
       "      <td>-336.995987</td>\n",
       "      <td>[-1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[-1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[-1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0.003042440870520857, -0.6412582352904221, -0...</td>\n",
       "      <td>[-6.987121025092691e-07, 4.78602190818328e-05,...</td>\n",
       "      <td>[-6.987121025092691e-07, 4.78602190818328e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, C, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-230.032860</td>\n",
       "      <td>-337.004116</td>\n",
       "      <td>[-1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[-1, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[-1, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0.003042440870520857, -0.6412582352904221, -0...</td>\n",
       "      <td>[1.3856579200721697e-07, 0.12122210162011998, ...</td>\n",
       "      <td>[1.3856579200721697e-07, 0.12122210162011998, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.459886</td>\n",
       "      <td>-340.400298</td>\n",
       "      <td>[-1, -1, 0, 0, 1, 1]</td>\n",
       "      <td>[-1, -1, 0, 0, 1, 1]</td>\n",
       "      <td>[-1, -1, 0, 0, 1, 1]</td>\n",
       "      <td>[0.0030420040635958934, -0.7624235284472971, -...</td>\n",
       "      <td>[0.0030420040635958934, -0.7624235284472971, -...</td>\n",
       "      <td>[0.0030420040635958934, -0.7624235284472971, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, C, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-233.463021</td>\n",
       "      <td>-340.318992</td>\n",
       "      <td>[-1, -1, 0, 0, 1, 1]</td>\n",
       "      <td>[-1, 0, -1, 0, 1, 1]</td>\n",
       "      <td>[-1, -1, 0, 1, 0, 1]</td>\n",
       "      <td>[0.0030420040635958934, -0.7624235284472971, -...</td>\n",
       "      <td>[-1.8574247866443017e-06, -1.4037413591460208,...</td>\n",
       "      <td>[0.00304284134149041, -0.6412492870462589, 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                charges                              elements   \n",
       "0  [7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]  [N, B, C, C, C, C, H, H, H, H, H, H]  \\\n",
       "1  [7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]  [N, C, B, C, C, C, H, H, H, H, H, H]   \n",
       "2  [7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]  [N, C, C, B, C, C, H, H, H, H, H, H]   \n",
       "3  [7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]  [N, N, B, B, C, C, H, H, H, H, H, H]   \n",
       "4  [7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]  [N, N, B, C, B, C, H, H, H, H, H, H]   \n",
       "\n",
       "   total energy  electronic energy             sorted_dx   \n",
       "0   -230.034644        -336.906006   [-1, 0, 0, 0, 0, 1]  \\\n",
       "1   -230.040119        -336.995987   [-1, 0, 0, 0, 0, 1]   \n",
       "2   -230.032860        -337.004116   [-1, 0, 0, 0, 0, 1]   \n",
       "3   -233.459886        -340.400298  [-1, -1, 0, 0, 1, 1]   \n",
       "4   -233.463021        -340.318992  [-1, -1, 0, 0, 1, 1]   \n",
       "\n",
       "                lexi_dx           lexi_opp_dx   \n",
       "0   [-1, 0, 0, 0, 0, 1]   [-1, 0, 0, 0, 0, 1]  \\\n",
       "1   [-1, 0, 0, 0, 1, 0]   [-1, 0, 0, 0, 1, 0]   \n",
       "2   [-1, 0, 0, 1, 0, 0]   [-1, 0, 0, 1, 0, 0]   \n",
       "3  [-1, -1, 0, 0, 1, 1]  [-1, -1, 0, 0, 1, 1]   \n",
       "4  [-1, 0, -1, 0, 1, 1]  [-1, -1, 0, 1, 0, 1]   \n",
       "\n",
       "                                            sorted_c   \n",
       "0  [0.003042440870520857, -0.6412582352904221, -0...  \\\n",
       "1  [0.003042440870520857, -0.6412582352904221, -0...   \n",
       "2  [0.003042440870520857, -0.6412582352904221, -0...   \n",
       "3  [0.0030420040635958934, -0.7624235284472971, -...   \n",
       "4  [0.0030420040635958934, -0.7624235284472971, -...   \n",
       "\n",
       "                                              lexi_c   \n",
       "0  [0.003042440870520857, -0.6412582352904221, -0...  \\\n",
       "1  [-6.987121025092691e-07, 4.78602190818328e-05,...   \n",
       "2  [1.3856579200721697e-07, 0.12122210162011998, ...   \n",
       "3  [0.0030420040635958934, -0.7624235284472971, -...   \n",
       "4  [-1.8574247866443017e-06, -1.4037413591460208,...   \n",
       "\n",
       "                                          lexi_opp_c  \n",
       "0  [0.003042440870520857, -0.6412582352904221, -0...  \n",
       "1  [-6.987121025092691e-07, 4.78602190818328e-05,...  \n",
       "2  [1.3856579200721697e-07, 0.12122210162011998, ...  \n",
       "3  [0.0030420040635958934, -0.7624235284472971, -...  \n",
       "4  [0.00304284134149041, -0.6412492870462589, 0.4...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the dx value as the different between target charge and reference charge\n",
    "ref_charge = [6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]\n",
    "ref_charge_array = np.tile(ref_charge, (17, 1))\n",
    "target_charge_array = np.array(benzene_data['charges'].tolist())\n",
    "dx_array = (target_charge_array - ref_charge_array)[:, :6] # only take the dx for C atoms\n",
    "\n",
    "# print(dx_array)\n",
    "\n",
    "# try different ways to sort the dx vector\n",
    "sorted_dx_array = np.sort(dx_array, axis=1) # sorted dx elements\n",
    "lexi_dx_array = lexi_transformation_2d(dx_array) # rotational and reflectional invariant\n",
    "lexi_opp_dx_array = lexi_and_opposite_transformation_2d(dx_array) # rotational, reflectional, and negation invariant\n",
    "\n",
    "print(sorted_dx_array.shape)\n",
    "print(lexi_dx_array.shape)\n",
    "print(lexi_opp_dx_array.shape)\n",
    "\n",
    "# Compute the c array, which represents the ANM coordinates\n",
    "sorted_c_array = (Q_inv @ sorted_dx_array.T).T\n",
    "lexi_c_array = (Q_inv @ lexi_dx_array.T).T\n",
    "lexi_opp_c_array = (Q_inv @ lexi_opp_dx_array.T).T\n",
    "\n",
    "# Append the data onto the dataframe\n",
    "benzene_data['sorted_dx'] = sorted_dx_array.tolist()\n",
    "benzene_data['lexi_dx'] = lexi_dx_array.tolist()\n",
    "benzene_data['lexi_opp_dx'] = lexi_opp_dx_array.tolist()\n",
    "benzene_data['sorted_c'] = sorted_c_array.tolist()\n",
    "benzene_data['lexi_c'] = lexi_c_array.tolist()\n",
    "benzene_data['lexi_opp_c'] = lexi_opp_c_array.tolist()\n",
    "\n",
    "\n",
    "# for i in range(len(c_array[0])):\n",
    "#     benzene_data[f\"coord{i}\"] = benzene_data['c'].apply(lambda x: x[i])\n",
    "\n",
    "display(benzene_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coordinates as six separate features\n",
    "columns = [f\"coord{i}\" for i in range(6)]\n",
    "X_sorted = pd.DataFrame(columns=columns)\n",
    "X_lexi = pd.DataFrame(columns=columns)\n",
    "X_lexi_opp = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(6):\n",
    "    X_sorted[f\"coord{i}\"] = benzene_data['sorted_c'].apply(lambda x: x[i] * 100)\n",
    "    X_lexi[f\"coord{i}\"] = benzene_data['lexi_c'].apply(lambda x: x[i] * 100)\n",
    "    X_lexi_opp[f\"coord{i}\"] = benzene_data['lexi_opp_c'].apply(lambda x: x[i] * 100)\n",
    "\n",
    "# Extract the targets\n",
    "\n",
    "y_energy = benzene_data['total energy']\n",
    "y_elec = benzene_data['electronic energy']\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ###\n",
    "\n",
    "P/G - Polynomial or Gaussian Kernel\n",
    "\n",
    "S/L/Lo - used feature: sorted_c / lexi_c / lexi_opp_c\n",
    "\n",
    "T/E - prediction: total energy / electronic energy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial KRR ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KRR: polynomial, lexi_opp_c, total energy ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial KRR:\n",
      "Fold 1: RMSE = 243.46004123242983\n",
      "Fold 2: RMSE = 58.24701372079402\n",
      "Fold 3: RMSE = 113.2140293124711\n",
      "Fold 4: RMSE = 95.22485869356323\n",
      "Fold 5: RMSE = 93.41278426201792\n",
      "Average MSE across all folds: 120.71174544425523\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': 1e-06, 'coef0': 10, 'degree': 4, 'kernel': 'poly'}\n",
    "KRR_PLoT = KernelRidge(**params)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    mse_scores = cross_val_score(KRR_PLoT, X_lexi_opp, y_energy, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    rmse_scores = np.sqrt(-mse_scores)  \n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_rmse = rmse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "print(\"Polynomial KRR:\")\n",
    "for fold, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {fold+1}: RMSE = {rmse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average MSE across all folds: {avg_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian KRR ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KRR: Gaussian, lexi_opp_c, total energy ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial KRR:\n",
      "Fold 1: RMSE = 3.1633316474058017\n",
      "Fold 2: RMSE = 2.8753259771718223\n",
      "Fold 3: RMSE = 3.731471384556762\n",
      "Fold 4: RMSE = 0.9744193165601209\n",
      "Fold 5: RMSE = 1.3587346428398883\n",
      "Average MSE across all folds: 2.4206565937068794\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': 5e-05, 'gamma': 1.6e-07, 'kernel': 'rbf'}\n",
    "KRR_GLoT = KernelRidge(**params)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(KRR_GLoT, X_lexi_opp, y_energy, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "rmse_scores = np.sqrt(-mse_scores)  \n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_rmse = rmse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "print(\"Polynomial KRR:\")\n",
    "for fold, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {fold+1}: RMSE = {rmse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average MSE across all folds: {avg_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression (non kernelized) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regression = Ridge(alpha=0.01)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(ridge_regression, X, y, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "mse_scores = -mse_scores  # Convert negative MSE scores to positive\n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_mse = mse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "for fold, mse in enumerate(mse_scores):\n",
    "    print(f\"Fold {fold+1}: MSE = {mse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average MSE across all folds: {avg_mse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial KRR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparam tuning\n",
    "# # Grid search round 1\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.logspace(np.log10(1e-5), np.log10(10), num=50),\n",
    "#     'kernel': ['poly'],  \n",
    "#     'degree': [2, 3, 4], \n",
    "#     'coef0': np.logspace(np.log10(1e-5), np.log10(100), num=50), \n",
    "# }\n",
    "\n",
    "# poly_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.filterwarnings(\"ignore\")\n",
    "#     grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "#     grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparam tuning\n",
    "# # Grid search round 2\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.logspace(np.log10(1e-7), np.log10(1e-5), num=20),\n",
    "#     'kernel': ['poly'],  \n",
    "#     'degree': [1, 2, 3], \n",
    "#     'coef0': np.logspace(np.log10(100), np.log10(1000), num=20), \n",
    "# }\n",
    "\n",
    "# poly_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.filterwarnings(\"ignore\")\n",
    "#     grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "#     grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparam tuning\n",
    "# # Grid search round 3\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.logspace(np.log10(1e-9), np.log10(1e-6), num=30),\n",
    "#     'kernel': ['poly'],  \n",
    "#     'degree': [1, 2, 3], \n",
    "#     'coef0': np.linspace(300, 400, num=21), \n",
    "# }\n",
    "\n",
    "# poly_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.filterwarnings(\"ignore\")\n",
    "#     grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "#     grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian KRR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 7.906043210907702e-06, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "Best Mean Squared Error: 6.886800637717728\n"
     ]
    }
   ],
   "source": [
    "# small alpha, small gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(10e-7), np.log10(10e-3), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(10e-7), np.log10(10e-3), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "KRR_GLoT = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(KRR_GLoT, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_opp, y_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-06, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Mean Squared Error: 41789.54380108347\n"
     ]
    }
   ],
   "source": [
    "# small alpha, large gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(10e-7), np.log10(10e-3), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(10e-3), np.log10(1), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "KRR_GLoT = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(KRR_GLoT, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_opp, y_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "Best Mean Squared Error: 29.514712738253742\n"
     ]
    }
   ],
   "source": [
    "# large alpha, small gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(10e-3), np.log10(1), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(10e-7), np.log10(10e-3), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "KRR_GLoT = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(KRR_GLoT, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_opp, y_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Mean Squared Error: 41790.79139470468\n"
     ]
    }
   ],
   "source": [
    "# large alpha, large gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(10e-3), np.log10(1), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(10e-3), np.log10(1), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "KRR_GLoT = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(KRR_GLoT, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_opp, y_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-06, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "Best Mean Squared Error: 5.301730705166797\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(10e-7, 10e-5, num=20),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(10e-7, 10e-5, num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "KRR_GLoT = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=17, shuffle=True, random_state=10)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(KRR_GLoT, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 2\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.logspace(np.log10(0.001), np.log10(0.1), num=10),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.logspace(np.log10(0.0001), np.log10(0.01), num=10),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 3\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(0.01, 0.02, num = 20),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.logspace(np.log10(0.00001), np.log10(0.0001), num=10),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 4\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(0.005, 0.01, num = 21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.logspace(np.log10(1e-06), np.log10(1e-05), num=10),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 5\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(0.001, 0.005, num=21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.logspace(np.log10(3e-06), np.log10(6e-05), num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 6\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(0.0005, 0.001, num=21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.linspace(2e-06, 4e-06, num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 7\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(5e-4, 7e-4, num=21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.linspace(1e-06, 2e-06, num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 8\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(3e-4, 5e-4, num=21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.linspace(1e-06, 2e-06, num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 9\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(1e-4, 3e-4, num=21),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.linspace(5e-07, 1e-06, num=20),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search round 10\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(5e-5, 1e-4, num=11),  # Regularization parameter controlling the L2 regularization term\n",
    "#     'gamma': np.linspace(1e-07, 5e-07, num=21),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "#     'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "# }\n",
    "\n",
    "\n",
    "# gaussian_KRR = KernelRidge()\n",
    "\n",
    "# k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "# grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and score\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 1\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': [0.1, 0.5, 1.0, 2.0],  # Regularization strength\n",
    "#     'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 2\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(1.5, 2.5, num=10),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 3\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(2.5, 3.5, num=10),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 4\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(3, 10, num=71, endpoint=True),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 5\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(10, 20, num=101, endpoint=True),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 6\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(20, 100, num=41, endpoint=True),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 7\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(100, 1000, num=91, endpoint=True),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Ridge regression model\n",
    "# # Round 8\n",
    "\n",
    "# ridge_model = Ridge()\n",
    "\n",
    "# # Define the hyperparameters to tune and their respective values\n",
    "# param_grid = {\n",
    "#     'alpha': np.linspace(210, 230, num=21, endpoint=True),  # Regularization strength\n",
    "#     'solver': ['auto'],  # Solver algorithm\n",
    "# }\n",
    "\n",
    "# # Perform grid search using cross-validation\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Retrieve the best hyperparameters and the corresponding mean squared error\n",
    "# best_params = grid_search.best_params_\n",
    "# best_mse = -grid_search.best_score_\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Learning Curve ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(model, X, y, num_training_sample, num_trials):\n",
    "\n",
    "    \"\"\" \n",
    "    Given the number of training samples used, \n",
    "    calculate the average and standard deviation of MSE across a certain number of trials.\n",
    "    For each trial, a specified number of training examples is used to train the model, \n",
    "    which is then evaluated on the rest of the data set.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): training data; size (N, m) where N is the number of training examples and m is the number of features\n",
    "        y (ndarray): target data; size (N, 1)\n",
    "        num_training_sample (int): the number of samples used for training\n",
    "        num_trials: the number of trials \n",
    "    \n",
    "    Returns:\n",
    "        average_error: the average MSE across all trials\n",
    "        std_dev_error: standard deviation of the error across all trials\n",
    "    \"\"\"\n",
    "\n",
    "    errors = []\n",
    "    test_size = 1.0 - num_training_sample/X.shape[0]\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        error = np.sqrt(mean_squared_error(y_val, y_pred)) # Root mean squared error\n",
    "        errors.append(error)\n",
    "    \n",
    "    average_error = np.mean(errors)\n",
    "    std_dev_error = np.std(errors)\n",
    "    return average_error, std_dev_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial kernel\n",
    "\n",
    "best_params_poly_KRR = {'alpha': 1e-06, 'coef0': 345.0, 'degree': 2, 'kernel': 'poly'}\n",
    "poly_KRR_model = KernelRidge(**best_params_poly_KRR)\n",
    "\n",
    "columns = ['training size', 'average RMSE', 'standard deviation']\n",
    "model_performance_poly_KRR = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [i for i in range(1, 17)]\n",
    "num_trials = 20\n",
    "\n",
    "for num_training_sample in training_size:\n",
    "    index = num_training_sample - 1\n",
    "    average_error, std_dev_error = evaluate_performance(poly_KRR_model, X, y, num_training_sample, num_trials)\n",
    "    model_performance_poly_KRR.at[index, 'training size'] = num_training_sample\n",
    "    model_performance_poly_KRR.at[index, 'average RMSE'] = average_error\n",
    "    model_performance_poly_KRR.at[index, 'standard deviation'] = std_dev_error/np.sqrt(num_trials)\n",
    "\n",
    "display(model_performance_poly_KRR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian KRR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_gaussian_KRR = {'alpha': 5e-05, 'gamma': 1.6e-07, 'kernel': 'rbf'}\n",
    "gaussian_KRR_model = KernelRidge(**best_params_gaussian_KRR)\n",
    "\n",
    "columns = ['training size', 'average RMSE', 'standard deviation']\n",
    "model_performance_gaussian_KRR = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [i for i in range(1, 17)]\n",
    "num_trials = 20\n",
    "\n",
    "for num_training_sample in training_size:\n",
    "    index = num_training_sample - 1\n",
    "    average_error, std_dev_error = evaluate_performance(gaussian_KRR_model, X, y, num_training_sample, num_trials)\n",
    "    model_performance_gaussian_KRR.at[index, 'training size'] = num_training_sample\n",
    "    model_performance_gaussian_KRR.at[index, 'average RMSE'] = average_error\n",
    "    model_performance_gaussian_KRR.at[index, 'standard deviation'] = std_dev_error/np.sqrt(num_trials)\n",
    "\n",
    "display(model_performance_gaussian_KRR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ridge_regression = {'alpha': 219, 'solver': 'auto'}\n",
    "\n",
    "ridge_model = Ridge(**best_params_ridge_regression)\n",
    "\n",
    "columns = ['training size', 'average RMSE', 'standard deviation']\n",
    "model_performance_ridge_regression = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [i for i in range(1, 17)]\n",
    "num_trials = 20\n",
    "\n",
    "for num_training_sample in training_size:\n",
    "    index = num_training_sample - 1\n",
    "    average_error, std_dev_error = evaluate_performance(ridge_model, X, y, num_training_sample, num_trials)\n",
    "    model_performance_ridge_regression.at[index, 'training size'] = num_training_sample\n",
    "    model_performance_ridge_regression.at[index, 'average RMSE'] = average_error\n",
    "    model_performance_ridge_regression.at[index, 'standard deviation'] = std_dev_error/np.sqrt(num_trials)\n",
    "\n",
    "display(model_performance_ridge_regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graph with error bar\n",
    "\n",
    "# graph_x = model_performance['training size']\n",
    "# graph_y = model_performance['average RMSE']\n",
    "# graph_error = model_performance['standard deviation']\n",
    "\n",
    "# # Set figure size\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Create line plot with error bars\n",
    "# plt.errorbar(graph_x, graph_y, yerr=graph_error, marker='o', linestyle='-', capsize=4)\n",
    "\n",
    "# # Set axis labels and title\n",
    "# plt.xlabel('Training Size')\n",
    "# plt.ylabel('Average RMSE')\n",
    "# plt.title('Learning curve for BN-doped benzene molecule energy prediction using polynomial KRR')\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "\n",
    "# # Save the figure as a PNG image\n",
    "# plt.savefig('[Benz] learning_curve_16_points.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_KRR['training size']\n",
    "y1 = model_performance_poly_KRR['average RMSE']\n",
    "y2 = model_performance_gaussian_KRR['average RMSE']\n",
    "y3 = model_performance_ridge_regression['average RMSE']\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x, y1, label='Polynomial KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y2, label='Gaussian KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y3, label='Ridge Regression', marker='o', linestyle='-', linewidth=2.5)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule energy prediction')\n",
    "plt.xlabel('Training Size (log)')\n",
    "plt.ylabel('Average RMSE [Ha] (log)')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=2)\n",
    "\n",
    "# yticks = [2**i for i in range(-4, 7)]\n",
    "yticks = [2**i for i in range(0, 7)]\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] learning_curve_16_points_no_err_bar.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Error Bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_KRR['training size']\n",
    "y1 = model_performance_poly_KRR['average RMSE']\n",
    "y2 = model_performance_gaussian_KRR['average RMSE']\n",
    "y3 = model_performance_ridge_regression['average RMSE']\n",
    "y1_error = model_performance_poly_KRR['standard deviation']\n",
    "y2_error = model_performance_gaussian_KRR['standard deviation']\n",
    "y3_error = model_performance_ridge_regression['standard deviation']\n",
    "\n",
    "# Plotting\n",
    "# plt.plot(x, y1, label='Polynomial KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "# plt.plot(x, y2, label='Gaussian KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "# plt.plot(x, y3, label='Ridge Regression', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.errorbar(x, y1, label='Polynomial KRR', yerr=y1_error, marker='o', linestyle='-', capsize=3)\n",
    "plt.errorbar(x, y2, label='Gaussian KRR', yerr=y2_error, marker='o', linestyle='-', capsize=3)\n",
    "plt.errorbar(x, y3, label='Ridge Regression', yerr=y3_error, marker='o', linestyle='-', capsize=3)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule energy prediction')\n",
    "plt.xlabel('Training Size (log)')\n",
    "plt.ylabel('Average RMSE [Ha] (log)')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=2)\n",
    "\n",
    "# yticks = [2**i for i in range(-4, 7)]\n",
    "yticks = [2**i for i in range(0, 7)]\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] learning_curve_16_points_with_err_bar.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a version without polynomial KRR, which performed the worst\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "x = model_performance_poly_KRR['training size']\n",
    "y1 = model_performance_poly_KRR['average RMSE']\n",
    "y2 = model_performance_gaussian_KRR['average RMSE']\n",
    "y3 = model_performance_ridge_regression['average RMSE']\n",
    "y2_error = model_performance_gaussian_KRR['standard deviation']\n",
    "y3_error = model_performance_ridge_regression['standard deviation']\n",
    "\n",
    "plt.errorbar(x, y2, label='Gaussian KRR', yerr=y2_error, marker='o', linestyle='-', capsize=3)\n",
    "plt.errorbar(x, y3, label='Ridge Regression', yerr=y3_error, marker='o', linestyle='-', capsize=3)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule energy prediction')\n",
    "plt.xlabel('Training Size (log)')\n",
    "plt.ylabel('Average RMSE [Ha] (log)')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=2)\n",
    "\n",
    "yticks = [2**i for i in range(0, 3)]\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] learning_curve_without_poly_KRR.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that contains the energies predicted by the model and the actual energy\n",
    "\n",
    "# Specifies the columns of the dataframe and create an empty dataframe\n",
    "columns = ['Elements', 'Poly KRR prediction', 'Gaussian KRR prediction', 'Ridge regression prediction', 'Actual energy']\n",
    "model_prediction = pd.DataFrame(columns=columns)\n",
    "\n",
    "# fill in elements and the actual energy values from the original benzene_data dataframe\n",
    "model_prediction['Elements'] = benzene_data['Elements']\n",
    "model_prediction['Actual energy'] = benzene_data['Energy']\n",
    "\n",
    "# fit the gaussian KRR and ridge regression model on the training set\n",
    "gaussian_KRR_model.fit(X, y)\n",
    "ridge_model.fit(X, y)\n",
    "poly_KRR_model.fit(X, y)\n",
    "\n",
    "# iterate through each row entry of the data\n",
    "for index, row in model_prediction.iterrows():\n",
    "    x_pred = X.loc[[index]] # extract the input to be predicted\n",
    "    \n",
    "    # predict energy using the two models\n",
    "    # the given prediction is in a list of one element. use [0] to extract the actual value\n",
    "    gaussian_prediction = gaussian_KRR_model.predict(x_pred)[0] \n",
    "    ridge_prediction = ridge_model.predict(x_pred)[0]\n",
    "    poly_prediction = poly_KRR_model.predict(x_pred)[0] \n",
    "    \n",
    "    # Record the prediction in the DataFrame\n",
    "    model_prediction.at[index, 'Poly KRR prediction'] = poly_prediction\n",
    "    model_prediction.at[index, 'Gaussian KRR prediction'] = gaussian_prediction\n",
    "    model_prediction.at[index, 'Ridge regression prediction'] = ridge_prediction\n",
    "\n",
    "# display the data\n",
    "display(model_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the results\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "x = [i for i in range(17)]\n",
    "y_pred_1 = model_prediction['Gaussian KRR prediction']\n",
    "y_pred_2 = model_prediction['Ridge regression prediction']\n",
    "y_pred_3 = model_prediction['Poly KRR prediction']\n",
    "y = model_prediction['Actual energy']\n",
    "\n",
    "plt.plot(x, y_pred_1, label='Gaussian KRR prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y_pred_2, label='Ridge regression prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y_pred_3, label='Poly KRR prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y, label='Actual energy', marker='o', linestyle='-', linewidth=2.5)\n",
    "\n",
    "plt.title('Comparing model prediction with actual energy')\n",
    "plt.xlabel('Element index')\n",
    "plt.ylabel('Energy [Ha]')\n",
    "plt.legend()\n",
    "\n",
    "yticks = np.linspace(-230, -240, num=11)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "plt.savefig('../Graph/[Benz] comparing_model_performance.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
