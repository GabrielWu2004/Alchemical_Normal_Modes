{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../../helper_code')\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import copy\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from helper_code.custom_kernel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = ['c', 'c_lexi', 'c_lexi_nd', 'CE', 'CE_lexi', 'CE_lexi_nd', 'CSE', 'CSE_lexi', 'CSE_lexi_nd']\n",
    "dataset_dict = {}\n",
    "\n",
    "for data in input_dataset:\n",
    "    dataset_dict[data] = pd.read_csv(f'../data/coronene_training_data/{data}.csv')\n",
    "\n",
    "delta_total_energy = pd.read_csv(f'../data/coronene_training_data/delta_total_energy.csv')\n",
    "delta_delta_total_energy = pd.read_csv(f'../data/coronene_training_data/delta_delta_total_energy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'kernel': 'rbf', 'gamma': 3.9810717055349776e-08, 'alpha': 1e-10}\n",
      "Best Root Mean Squared Error: 0.1489627308333547\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-13), np.log10(1e-3), num=101),  \n",
    "    'gamma': np.logspace(np.log10(1e-13), np.log10(1e-3), num=101),  \n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "model = KernelRidge()\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid_search = RandomizedSearchCV(model, param_grid, n_iter=500, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-09, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.15033871067431506\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-9), np.log10(1e-7), num=21),  \n",
    "    'gamma': np.logspace(np.log10(1e-11), np.log10(1e-9), num=21),  \n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "model = KernelRidge()\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 2.5118864315095823e-11, 'gamma': 1.9952623149688786e-08, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.14895567868685927\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-11), np.log10(1e-9), num=21),  \n",
    "    'gamma': np.logspace(np.log10(1e-9), np.log10(1e-7), num=21),  \n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "model = KernelRidge()\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 4.6e-11, 'gamma': 2.8000000000000003e-08, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.14895286776797315\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-11, 5e-11, num=21),  \n",
    "    'gamma': np.linspace(1e-8, 5e-8, num=21),  \n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "model = KernelRidge()\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Opt ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:51<00:00,  1.22trial/s, best loss: 0.10696031336577831]\n",
      "Best hyperparameters: {'alpha': 1.6596764933651303e-07, 'gamma': 2.1567299387422978e-06}\n",
      "Loss: 0.10696031336577831\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=500,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.10695381401867467]\n",
      "CSE_lexi_nd\n",
      "Best hyperparameters: {'alpha': 1.5563301230102018e-07, 'gamma': 2.545548038867767e-06}\n",
      "Loss: 0.10695381401867467\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi_nd'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=100,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"CSE_lexi_nd\")\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Opt -- Extended Gaussian ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:38<00:00,  1.59s/trial, best loss: 0.10622358626175384]\n",
      "CSE_lexi, Extended Gaussian\n",
      "Best hyperparameters: {'alpha': 5.948688011403127e-11, 'beta': 2.8505311767038538e-12, 'epsilon': 4.727331943165293e-07, 'gamma': 5.298346661430054e-10}\n",
      "Loss: 0.10622358626175384\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "def objective(params):    \n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = vectorized_similarity_matrix(X_train, X_train, vectorized_extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    neg_mae_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "    'epsilon': hp.loguniform('epsilon', -30, 0), \n",
    "    'beta': hp.loguniform('beta', -30, 0), \n",
    "    'alpha': hp.loguniform('alpha', -30, 0) \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=param_space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=100,\n",
    "                trials=trials)\n",
    "    \n",
    "print(\"CSE_lexi, Extended Gaussian\")\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE - XGBRegressor ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:59<00:00,  3.00s/trial, best loss: 0.4910823526365557]\n",
      "CSE_xgboost\n",
      "Best hyperparameters: {'alpha': 5.573350082885807e-06, 'gamma': 0.49016228208008483, 'lambda': 0.03579084203303872, 'max_depth': 0}\n",
      "Loss: 0.4910823526365557\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "def objective(params):\n",
    "    params['objective'] = 'reg:squarederror'\n",
    "    params['n_estimators'] = 100\n",
    "    params['learning_rate'] = 0.05\n",
    "    params['subsample'] = 0.8\n",
    "    params['colsample_bytree'] = 0.8\n",
    "    model = XGBRegressor(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(5, 25)),\n",
    "    'gamma': hp.uniform('gamma', 0, 10),\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'lambda': hp.loguniform('lambda', -30, 0)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=100,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"CSE_xgboost\")\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Opt -- Coulomb Matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_rep = pd.read_csv(\"../data/coronene_training_data/CM_rep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:21<00:00,  1.07s/trial, best loss: 0.581003222550443] \n",
      "CSE_lexi_nd\n",
      "Best hyperparameters: {'alpha': 0.00011806857533747571, 'gamma': 0.00010582969605609149}\n",
      "Loss: 0.581003222550443\n"
     ]
    }
   ],
   "source": [
    "X_train = CM_rep.to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"CSE_lexi_nd\")\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.genfromtxt(\"../data/coronene_training_data/MBDF.csv\", delimiter=',')\n",
    "y_train = delta_total_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:26<00:00,  1.16trial/s, best loss: 0.12194094530689155]\n",
      "MBDF\n",
      "Best hyperparameters: {'alpha': 5.300500381866468e-13, 'gamma': 9.287160666894478e-05}\n",
      "Loss: 0.12194094530689155\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=100,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"MBDF\")\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
