{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../../helper_code')\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numba\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "from helper_code.custom_kernel import create_similarity_matrix_nb, extended_gaussian_kernel_nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = ['c', 'c_lexi', 'CE', 'CE_lexi', 'CSE', 'CSE_lexi']\n",
    "dataset_dict = {}\n",
    "\n",
    "for data in input_dataset:\n",
    "    dataset_dict[data] = pd.read_csv(f'../data/coronene_training_data/{data}.csv')\n",
    "    dataset_dict[f\"IDM_{data}\"] = pd.read_csv(f'../data/coronene_training_data/[IDM]{data}.csv')\n",
    "\n",
    "D_etot = pd.read_csv(f'../data/coronene_training_data/delta_total_energy.csv')\n",
    "DD_etot = pd.read_csv(f'../data/coronene_training_data/DD_e_tot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE with Gaussian Kernel ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No lexi, D_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.10517346003262494\n",
      "Fold 2: MAE = 0.10475856493434792\n",
      "Average MAE across all folds: 0.10496601248348643\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 2.2425013674157485e-08, 'gamma': 8.136151536502313e-08, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "mae_scores = -neg_mae_scores\n",
    "avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:29<00:00, 10.14trial/s, best loss: 0.10496601248348643]\n",
      "Best hyperparameters: {'alpha': 2.2425013674157485e-08, 'gamma': 8.136151536502313e-08}\n",
      "Loss: 0.10496601248348643\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "X_train = dataset_dict['CSE'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexi, D_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.10401053546423987\n",
      "Fold 2: MAE = 0.10143435614903583\n",
      "Average MAE across all folds: 0.10272244580663785\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = D_etot\n",
    "\n",
    "params = {'alpha': 1.5182042161569614e-12, 'gamma': 6.03689365016129e-10, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "mae_scores = -neg_mae_scores\n",
    "avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:30<00:00,  9.98trial/s, best loss: 0.10272244580663785]\n",
      "Best hyperparameters: {'alpha': 1.5182042161569614e-12, 'gamma': 6.03689365016129e-10}\n",
      "Loss: 0.10272244580663785\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexi, DD_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.1001863077773452\n",
      "Fold 2: MAE = 0.09583078624793348\n",
      "Average MAE across all folds: 0.09800854701263934\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = DD_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 0.0025629074500422688, 'gamma': 1.8104490522288843e-07, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "mae_scores = -neg_mae_scores\n",
    "avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:31<00:00,  9.46trial/s, best loss: 0.09800854701263934]\n",
      "Best hyperparameters: {'alpha': 0.0025629074500422688, 'gamma': 1.8104490522288843e-07}\n",
      "Loss: 0.09800854701263934\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = DD_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Gaussian ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Lexi, D_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.10543877330951051\n",
      "Fold 2: MAE = 0.10505898667621821\n",
      "Average MAE across all folds: 0.10524887999286436\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 4.078182747775911e-06, 'beta': 1.9601587086085153e-06, 'epsilon': 3.757467077768846e-11, 'gamma': 3.592110159724421e-13}\n",
    "beta = params['beta']\n",
    "epsilon = params['epsilon']\n",
    "gamma = params['gamma']\n",
    "alpha = params['alpha']\n",
    "\n",
    "similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mae = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    mae_scores = -neg_mae\n",
    "    avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:19<00:00,  3.77trial/s, best loss: 0.10524887999286436]\n",
      "Best hyperparameters: {'alpha': 4.078182747775911e-06, 'beta': 1.9601587086085153e-06, 'epsilon': 3.757467077768846e-11, 'gamma': 3.592110159724421e-13}\n",
      "Loss: 0.10524887999286436\n"
     ]
    }
   ],
   "source": [
    "# Tuning \n",
    "\n",
    "X_train = dataset_dict['CSE'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    beta = params['beta']\n",
    "    epsilon = params['epsilon']\n",
    "    gamma = params['gamma']\n",
    "    alpha = params['alpha']\n",
    "    similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    neg_mae_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'gamma': hp.loguniform('gamma', -30, 2),\n",
    "    'epsilon': hp.loguniform('epsilon', -30, 2), \n",
    "    'beta': hp.loguniform('beta', -30, 2), \n",
    "    'alpha': hp.loguniform('alpha', -30, 2) \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=param_space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "    \n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexi, D_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.1041707581587638\n",
      "Fold 2: MAE = 0.10341720396456694\n",
      "Average MAE across all folds: 0.10379398106166537\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 4.082588287978896e-08, 'beta': 2.0167466950900717e-07, 'epsilon': 2.142512351831609e-08, 'gamma': 4.181167988054245e-09}\n",
    "beta = params['beta']\n",
    "epsilon = params['epsilon']\n",
    "gamma = params['gamma']\n",
    "alpha = params['alpha']\n",
    "\n",
    "similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mae = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    mae_scores = -neg_mae\n",
    "    avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:17<00:00,  3.89trial/s, best loss: 0.10379398106166537]\n",
      "Best hyperparameters: {'alpha': 4.082588287978896e-08, 'beta': 2.0167466950900717e-07, 'epsilon': 2.142512351831609e-08, 'gamma': 4.181167988054245e-09}\n",
      "Loss: 0.10379398106166537\n"
     ]
    }
   ],
   "source": [
    "# Tuning \n",
    "\n",
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    beta = params['beta']\n",
    "    epsilon = params['epsilon']\n",
    "    gamma = params['gamma']\n",
    "    alpha = params['alpha']\n",
    "    similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    neg_mae_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'gamma': hp.loguniform('gamma', -30, 2),\n",
    "    'epsilon': hp.loguniform('epsilon', -30, 2), \n",
    "    'beta': hp.loguniform('beta', -30, 2), \n",
    "    'alpha': hp.loguniform('alpha', -30, 2) \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=param_space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "    \n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexi, DD_etot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.09553401338682989\n",
      "Fold 2: MAE = 0.09599543075525488\n",
      "Average MAE across all folds: 0.09576472207104239\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy(dtype=np.float64)\n",
    "y_train = DD_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 0.00028513857657025936, 'beta': 1.1753499166909471e-08, 'epsilon': 3.0350353283034606e-06, 'gamma': 1.1611337892690983e-07}\n",
    "beta = params['beta']\n",
    "epsilon = params['epsilon']\n",
    "gamma = params['gamma']\n",
    "alpha = params['alpha']\n",
    "\n",
    "similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "# print(similarity_matrix.shape)\n",
    "krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mae = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    mae_scores = -neg_mae\n",
    "    avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:17<00:00,  3.87trial/s, best loss: 0.09576472207104239]\n",
      "Best hyperparameters: {'alpha': 0.00028513857657025936, 'beta': 1.1753499166909471e-08, 'epsilon': 3.0350353283034606e-06, 'gamma': 1.1611337892690983e-07}\n",
      "Loss: 0.09576472207104239\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['CSE_lexi'].to_numpy()\n",
    "y_train = DD_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    beta = params['beta']\n",
    "    epsilon = params['epsilon']\n",
    "    gamma = params['gamma']\n",
    "    alpha = params['alpha']\n",
    "    similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    neg_mae_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'gamma': hp.loguniform('gamma', -30, 2),\n",
    "    'epsilon': hp.loguniform('epsilon', -30, 2), \n",
    "    'beta': hp.loguniform('beta', -30, 2), \n",
    "    'alpha': hp.loguniform('alpha', -30, 2) \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=param_space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "    \n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.10353586198509138\n",
      "Fold 2: MAE = 0.1006480394548003\n",
      "Average MAE across all folds: 0.10209195071994584\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['IDM_CSE_lexi'].to_numpy()\n",
    "y_train = D_etot\n",
    "\n",
    "params = {'alpha': 2.9143654132589253e-13, 'gamma': 9.452129457528114e-10, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    mae_scores = -neg_mae_scores\n",
    "    avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:07<00:00,  2.35trial/s, best loss: 0.10209195071994584]\n",
      "Best hyperparameters: {'alpha': 2.9143654132589253e-13, 'gamma': 9.452129457528114e-10}\n",
      "Loss: 0.10209195071994584\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "\n",
    "X_train = dataset_dict['IDM_CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    params['kernel'] = 'rbf'\n",
    "    model = KernelRidge(**params)\n",
    "    neg_mae_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'alpha': hp.loguniform('alpha', -30, 0),\n",
    "    'gamma': hp.loguniform('gamma', -30, 0),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MAE = 0.10372669507359933\n",
      "Fold 2: MAE = 0.10435532744275194\n",
      "Average MAE across all folds: 0.10404101125817564\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_dict['IDM_CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "params = {'alpha': 3.675729391358022e-12, 'beta': 7.50981822257169e-09, 'epsilon': 1.0596237543876683e-08, 'gamma': 9.718114533626386e-14}\n",
    "beta = params['beta']\n",
    "epsilon = params['epsilon']\n",
    "gamma = params['gamma']\n",
    "alpha = params['alpha']\n",
    "\n",
    "similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mae = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    mae_scores = -neg_mae\n",
    "    avg_mae = mae_scores.mean()\n",
    "\n",
    "for fold, mae in enumerate(mae_scores):\n",
    "    print(f\"Fold {fold+1}: MAE = {mae}\")\n",
    "print(f\"Average MAE across all folds: {avg_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [07:27<00:00,  1.49s/trial, best loss: 0.10404101125817564]\n",
      "Best hyperparameters: {'alpha': 3.675729391358022e-12, 'beta': 7.50981822257169e-09, 'epsilon': 1.0596237543876683e-08, 'gamma': 9.718114533626386e-14}\n",
      "Loss: 0.10404101125817564\n"
     ]
    }
   ],
   "source": [
    "# Tuning \n",
    "\n",
    "X_train = dataset_dict['IDM_CSE_lexi'].to_numpy()\n",
    "y_train = D_etot.to_numpy()\n",
    "\n",
    "def objective(params):\n",
    "    beta = params['beta']\n",
    "    epsilon = params['epsilon']\n",
    "    gamma = params['gamma']\n",
    "    alpha = params['alpha']\n",
    "    similarity_matrix = create_similarity_matrix_nb(X_train, X_train, extended_gaussian_kernel_nb, beta, epsilon, gamma)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    neg_mae_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_absolute_error', cv=2)\n",
    "    return {'loss': -neg_mae_scores.mean(), 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'gamma': hp.loguniform('gamma', -30, 2),\n",
    "    'epsilon': hp.loguniform('epsilon', -30, 2), \n",
    "    'beta': hp.loguniform('beta', -30, 2), \n",
    "    'alpha': hp.loguniform('alpha', -30, 2) \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=param_space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=300,\n",
    "                trials=trials)\n",
    "    \n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coulombic Matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coord0</th>\n",
       "      <th>coord1</th>\n",
       "      <th>coord2</th>\n",
       "      <th>coord3</th>\n",
       "      <th>coord4</th>\n",
       "      <th>coord5</th>\n",
       "      <th>coord6</th>\n",
       "      <th>coord7</th>\n",
       "      <th>coord8</th>\n",
       "      <th>coord9</th>\n",
       "      <th>...</th>\n",
       "      <th>coord656</th>\n",
       "      <th>coord657</th>\n",
       "      <th>coord658</th>\n",
       "      <th>coord659</th>\n",
       "      <th>coord660</th>\n",
       "      <th>coord661</th>\n",
       "      <th>coord662</th>\n",
       "      <th>coord663</th>\n",
       "      <th>coord664</th>\n",
       "      <th>coord665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.358707</td>\n",
       "      <td>34.053598</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>34.368323</td>\n",
       "      <td>19.751342</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>12.913381</td>\n",
       "      <td>19.751462</td>\n",
       "      <td>9.875736</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402831</td>\n",
       "      <td>0.119825</td>\n",
       "      <td>0.399055</td>\n",
       "      <td>0.146940</td>\n",
       "      <td>0.103771</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>0.107468</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.119824</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.358707</td>\n",
       "      <td>19.751342</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>12.913317</td>\n",
       "      <td>8.552605</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>19.885231</td>\n",
       "      <td>11.390971</td>\n",
       "      <td>9.539765</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399079</td>\n",
       "      <td>0.107396</td>\n",
       "      <td>0.119824</td>\n",
       "      <td>0.402834</td>\n",
       "      <td>0.107468</td>\n",
       "      <td>0.146938</td>\n",
       "      <td>0.146572</td>\n",
       "      <td>0.207540</td>\n",
       "      <td>0.103772</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.358707</td>\n",
       "      <td>34.368245</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>19.751462</td>\n",
       "      <td>17.105333</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>19.751342</td>\n",
       "      <td>17.105179</td>\n",
       "      <td>9.875736</td>\n",
       "      <td>53.358707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207545</td>\n",
       "      <td>0.119824</td>\n",
       "      <td>0.146570</td>\n",
       "      <td>0.402824</td>\n",
       "      <td>0.107395</td>\n",
       "      <td>0.107468</td>\n",
       "      <td>0.207542</td>\n",
       "      <td>0.146940</td>\n",
       "      <td>0.399078</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coord0     coord1     coord2     coord3     coord4     coord5   \n",
       "0  53.358707  34.053598  53.358707  34.368323  19.751342  53.358707  \\\n",
       "1  53.358707  19.751342  53.358707  12.913317   8.552605  53.358707   \n",
       "2  53.358707  34.368245  53.358707  19.751462  17.105333  53.358707   \n",
       "\n",
       "      coord6     coord7    coord8     coord9  ...  coord656  coord657   \n",
       "0  12.913381  19.751462  9.875736  53.358707  ...  0.402831  0.119825  \\\n",
       "1  19.885231  11.390971  9.539765  53.358707  ...  0.399079  0.107396   \n",
       "2  19.751342  17.105179  9.875736  53.358707  ...  0.207545  0.119824   \n",
       "\n",
       "   coord658  coord659  coord660  coord661  coord662  coord663  coord664   \n",
       "0  0.399055  0.146940  0.103771  0.207540  0.107468  0.207544  0.119824  \\\n",
       "1  0.119824  0.402834  0.107468  0.146938  0.146572  0.207540  0.103772   \n",
       "2  0.146570  0.402824  0.107395  0.107468  0.207542  0.146940  0.399078   \n",
       "\n",
       "   coord665  \n",
       "0       0.5  \n",
       "1       0.5  \n",
       "2       0.5  \n",
       "\n",
       "[3 rows x 666 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM_rep = pd.read_csv(\"../data/coronene_training_data/CM_rep.csv\")\n",
    "display(CM_rep.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: rmse = 1.0627929185395568\n",
      "fold 1: rmse = 1.0286874440862068\n",
      "Average rmse: 1.045740181312882\n"
     ]
    }
   ],
   "source": [
    "X_train = CM_rep.to_numpy()\n",
    "y_train = delta_delta_total_energy\n",
    "\n",
    "params = {'alpha': 4.6e-11, 'gamma': 2.8e-08, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "neg_mse_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=2)\n",
    "rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "mean_rmse_score = rmse_scores.mean()\n",
    "\n",
    "for fold, score in enumerate(rmse_scores):\n",
    "    print(f\"fold {fold}: rmse = {score}\")\n",
    "\n",
    "print(f\"Average rmse: {mean_rmse_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: rmse = 0.22988854923839755\n",
      "fold 1: rmse = 0.22332026844768935\n",
      "Average rmse: 0.22660440884304345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.96887e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.67816e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.genfromtxt(\"../data/coronene_training_data/MBDF.csv\", delimiter=',')\n",
    "y_train = delta_total_energy\n",
    "\n",
    "params = {'alpha': 5.300500381866468e-13, 'gamma': 9.287160666894478e-05, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    neg_mse_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=2)\n",
    "    rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "    mean_rmse_score = rmse_scores.mean()\n",
    "\n",
    "for fold, score in enumerate(rmse_scores):\n",
    "    print(f\"fold {fold}: rmse = {score}\")\n",
    "\n",
    "print(f\"Average rmse: {mean_rmse_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
