{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../../APDFT')\n",
    "sys.path.append('../../helper_code')\n",
    "sys.path.append('../data')\n",
    "\n",
    "import pickle\n",
    "from pyscf import gto, scf, dft, cc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import basis_set_exchange as bse\n",
    "from APDFT.FcMole import *\n",
    "import os\n",
    "import ast\n",
    "from copy import deepcopy\n",
    "from IPython.display import display\n",
    "from helper_code.data_processing import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from APDFT.AP_class import APDFT_perturbator as AP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the atomic coordinates of benzene molecule (the reference molecule for ANM calculations)\n",
    "\n",
    "benz_atom=\"\"\"\n",
    "C        3.22272669       0.22711285       0.00013582\n",
    "C        5.87141753       0.22698034       0.00094988\n",
    "C        7.19597908       2.52071412      -0.00011471\n",
    "C        5.87164800       4.81458054      -0.00200817\n",
    "C        3.22295713       4.81471307      -0.00280461\n",
    "C        1.89839559       2.52097926      -0.00174231\n",
    "H        2.18773340      -1.56549239       0.00096741\n",
    "H        6.90623079      -1.56572844       0.00241360\n",
    "H        9.26591446       2.52061061       0.00051784\n",
    "H        6.90664130       6.60718579      -0.00284841\n",
    "H        2.18814386       6.60742187      -0.00426425\n",
    "H       -0.17153979       2.52108280      -0.00237226\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_pcx2={\"H\":\"pc-2\",'C':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[6])\\\n",
    "           ,'N':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[7])\\\n",
    "           ,'O':bse.get_basis(\"pcX-2\",fmt=\"nwchem\",elements=[8])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "      <th>elements</th>\n",
       "      <th>total energy</th>\n",
       "      <th>electronic energy</th>\n",
       "      <th>delta total energy</th>\n",
       "      <th>delta electronic energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, C, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-232.488488</td>\n",
       "      <td>-336.906006</td>\n",
       "      <td>2.576317</td>\n",
       "      <td>-0.077315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, B, C, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-232.427609</td>\n",
       "      <td>-336.995987</td>\n",
       "      <td>2.515439</td>\n",
       "      <td>0.012665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, C, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-232.433092</td>\n",
       "      <td>-337.004116</td>\n",
       "      <td>2.520922</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, B, C, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.671427</td>\n",
       "      <td>-340.400298</td>\n",
       "      <td>5.759256</td>\n",
       "      <td>3.416976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, C, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.708812</td>\n",
       "      <td>-340.318992</td>\n",
       "      <td>5.796641</td>\n",
       "      <td>3.335670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[7, 7, 5, 6, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, C, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-235.785018</td>\n",
       "      <td>-340.193778</td>\n",
       "      <td>5.872848</td>\n",
       "      <td>3.210456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[7, 7, 6, 5, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, C, B, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.595264</td>\n",
       "      <td>-340.510269</td>\n",
       "      <td>5.683093</td>\n",
       "      <td>3.526948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[7, 5, 7, 6, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, C, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-235.875126</td>\n",
       "      <td>-340.067245</td>\n",
       "      <td>5.962955</td>\n",
       "      <td>3.083924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[7, 5, 7, 6, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, C, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.813393</td>\n",
       "      <td>-340.126176</td>\n",
       "      <td>5.901222</td>\n",
       "      <td>3.142854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[7, 6, 7, 5, 5, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, N, B, B, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.694052</td>\n",
       "      <td>-340.325617</td>\n",
       "      <td>5.781881</td>\n",
       "      <td>3.342296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[7, 6, 7, 5, 6, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, N, B, C, B, H, H, H, H, H, H]</td>\n",
       "      <td>-235.795788</td>\n",
       "      <td>-340.168325</td>\n",
       "      <td>5.883617</td>\n",
       "      <td>3.185004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[5, 7, 5, 6, 7, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[B, N, B, C, N, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.808593</td>\n",
       "      <td>-340.122083</td>\n",
       "      <td>5.896423</td>\n",
       "      <td>3.138762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[7, 6, 6, 7, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, C, C, N, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-235.770160</td>\n",
       "      <td>-340.209091</td>\n",
       "      <td>5.857989</td>\n",
       "      <td>3.225769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 7, 6, 5, 7, 6, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[B, N, C, B, N, C, H, H, H, H, H, H]</td>\n",
       "      <td>-235.809538</td>\n",
       "      <td>-340.108576</td>\n",
       "      <td>5.897367</td>\n",
       "      <td>3.125255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[7, 7, 7, 5, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, N, B, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-238.892490</td>\n",
       "      <td>-343.827059</td>\n",
       "      <td>8.980319</td>\n",
       "      <td>6.843738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[7, 7, 5, 7, 5, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, N, B, N, B, B, H, H, H, H, H, H]</td>\n",
       "      <td>-239.124727</td>\n",
       "      <td>-343.423752</td>\n",
       "      <td>9.212556</td>\n",
       "      <td>6.440431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[7, 5, 7, 5, 7, 5, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[N, B, N, B, N, B, H, H, H, H, H, H]</td>\n",
       "      <td>-239.314977</td>\n",
       "      <td>-343.085881</td>\n",
       "      <td>9.402806</td>\n",
       "      <td>6.102560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 charges   \n",
       "0   [7, 5, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1]  \\\n",
       "1   [7, 6, 5, 6, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "2   [7, 6, 6, 5, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "3   [7, 7, 5, 5, 6, 6, 1, 1, 1, 1, 1, 1]   \n",
       "4   [7, 7, 5, 6, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "5   [7, 7, 5, 6, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "6   [7, 7, 6, 5, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "7   [7, 5, 7, 6, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "8   [7, 5, 7, 6, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "9   [7, 6, 7, 5, 5, 6, 1, 1, 1, 1, 1, 1]   \n",
       "10  [7, 6, 7, 5, 6, 5, 1, 1, 1, 1, 1, 1]   \n",
       "11  [5, 7, 5, 6, 7, 6, 1, 1, 1, 1, 1, 1]   \n",
       "12  [7, 6, 6, 7, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "13  [5, 7, 6, 5, 7, 6, 1, 1, 1, 1, 1, 1]   \n",
       "14  [7, 7, 7, 5, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "15  [7, 7, 5, 7, 5, 5, 1, 1, 1, 1, 1, 1]   \n",
       "16  [7, 5, 7, 5, 7, 5, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                elements  total energy  electronic energy   \n",
       "0   [N, B, C, C, C, C, H, H, H, H, H, H]   -232.488488        -336.906006  \\\n",
       "1   [N, C, B, C, C, C, H, H, H, H, H, H]   -232.427609        -336.995987   \n",
       "2   [N, C, C, B, C, C, H, H, H, H, H, H]   -232.433092        -337.004116   \n",
       "3   [N, N, B, B, C, C, H, H, H, H, H, H]   -235.671427        -340.400298   \n",
       "4   [N, N, B, C, B, C, H, H, H, H, H, H]   -235.708812        -340.318992   \n",
       "5   [N, N, B, C, C, B, H, H, H, H, H, H]   -235.785018        -340.193778   \n",
       "6   [N, N, C, B, B, C, H, H, H, H, H, H]   -235.595264        -340.510269   \n",
       "7   [N, B, N, C, C, B, H, H, H, H, H, H]   -235.875126        -340.067245   \n",
       "8   [N, B, N, C, B, C, H, H, H, H, H, H]   -235.813393        -340.126176   \n",
       "9   [N, C, N, B, B, C, H, H, H, H, H, H]   -235.694052        -340.325617   \n",
       "10  [N, C, N, B, C, B, H, H, H, H, H, H]   -235.795788        -340.168325   \n",
       "11  [B, N, B, C, N, C, H, H, H, H, H, H]   -235.808593        -340.122083   \n",
       "12  [N, C, C, N, B, B, H, H, H, H, H, H]   -235.770160        -340.209091   \n",
       "13  [B, N, C, B, N, C, H, H, H, H, H, H]   -235.809538        -340.108576   \n",
       "14  [N, N, N, B, B, B, H, H, H, H, H, H]   -238.892490        -343.827059   \n",
       "15  [N, N, B, N, B, B, H, H, H, H, H, H]   -239.124727        -343.423752   \n",
       "16  [N, B, N, B, N, B, H, H, H, H, H, H]   -239.314977        -343.085881   \n",
       "\n",
       "    delta total energy  delta electronic energy  \n",
       "0             2.576317                -0.077315  \n",
       "1             2.515439                 0.012665  \n",
       "2             2.520922                 0.020794  \n",
       "3             5.759256                 3.416976  \n",
       "4             5.796641                 3.335670  \n",
       "5             5.872848                 3.210456  \n",
       "6             5.683093                 3.526948  \n",
       "7             5.962955                 3.083924  \n",
       "8             5.901222                 3.142854  \n",
       "9             5.781881                 3.342296  \n",
       "10            5.883617                 3.185004  \n",
       "11            5.896423                 3.138762  \n",
       "12            5.857989                 3.225769  \n",
       "13            5.897367                 3.125255  \n",
       "14            8.980319                 6.843738  \n",
       "15            9.212556                 6.440431  \n",
       "16            9.402806                 6.102560  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dest_csv_path = \"../data/benzene_processed_data/benzene_energy_data.csv\"\n",
    "raw_tot_energy_path = \"../data/benzene_raw_data/Benzene_BNdoping_PBE0_pcX2_opt.npz\"\n",
    "row_elec_energy_path = \"../data/benzene_raw_data/Benzene_BNdoping_PBE0_pcX2_opt_electronic.npz\"\n",
    "benzene_energy_data = load_data(benz_atom, basis_pcx2, dest_csv_path, raw_tot_energy_path, raw_tot_energy_path)\n",
    "display(benzene_energy_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular Representation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian-based ANM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.61645906 -3.59391232 -3.56441216 -3.50145981 -3.51709044 -3.51211196]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.375838</td>\n",
       "      <td>0.163026</td>\n",
       "      <td>0.150611</td>\n",
       "      <td>0.139364</td>\n",
       "      <td>0.164915</td>\n",
       "      <td>0.143651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.163026</td>\n",
       "      <td>-3.375836</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>0.164914</td>\n",
       "      <td>0.139366</td>\n",
       "      <td>0.150608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150611</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>-3.401051</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>0.150607</td>\n",
       "      <td>0.191661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139364</td>\n",
       "      <td>0.164914</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>-3.375837</td>\n",
       "      <td>0.163026</td>\n",
       "      <td>0.150610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164915</td>\n",
       "      <td>0.139366</td>\n",
       "      <td>0.150607</td>\n",
       "      <td>0.163026</td>\n",
       "      <td>-3.375835</td>\n",
       "      <td>0.143651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143651</td>\n",
       "      <td>0.150608</td>\n",
       "      <td>0.191661</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>0.143651</td>\n",
       "      <td>-3.401048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -3.375838  0.163026  0.150611  0.139364  0.164915  0.143651\n",
       "1  0.163026 -3.375836  0.143651  0.164914  0.139366  0.150608\n",
       "2  0.150611  0.143651 -3.401051  0.143651  0.150607  0.191661\n",
       "3  0.139364  0.164914  0.143651 -3.375837  0.163026  0.150610\n",
       "4  0.164915  0.139366  0.150607  0.163026 -3.375835  0.143651\n",
       "5  0.143651  0.150608  0.191661  0.150610  0.143651 -3.401048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.409260</td>\n",
       "      <td>-0.060626</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.287227</td>\n",
       "      <td>0.499965</td>\n",
       "      <td>0.496332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.409260</td>\n",
       "      <td>0.060588</td>\n",
       "      <td>-0.499980</td>\n",
       "      <td>0.287228</td>\n",
       "      <td>0.500048</td>\n",
       "      <td>-0.496293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.406216</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.578764</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.085726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.409260</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>0.500007</td>\n",
       "      <td>0.287202</td>\n",
       "      <td>-0.499964</td>\n",
       "      <td>-0.496365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.409261</td>\n",
       "      <td>-0.060578</td>\n",
       "      <td>-0.499991</td>\n",
       "      <td>0.287298</td>\n",
       "      <td>-0.500023</td>\n",
       "      <td>0.496268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.406218</td>\n",
       "      <td>-0.701884</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.578798</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.085668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -0.409260 -0.060626  0.500021  0.287227  0.499965  0.496332\n",
       "1 -0.409260  0.060588 -0.499980  0.287228  0.500048 -0.496293\n",
       "2 -0.406216  0.701905 -0.000014 -0.578764  0.000001  0.085726\n",
       "3 -0.409260  0.060596  0.500007  0.287202 -0.499964 -0.496365\n",
       "4 -0.409261 -0.060578 -0.499991  0.287298 -0.500023  0.496268\n",
       "5 -0.406218 -0.701884 -0.000042 -0.578798 -0.000027 -0.085668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = get_hessian()\n",
    "Q_eig_val, Q = np.linalg.eig(H)\n",
    "np.savetxt('CCS_basis/ANM_basis.txt', Q)\n",
    "\n",
    "H_df = pd.DataFrame(H)\n",
    "Q_df = pd.DataFrame(Q)\n",
    "print(Q_eig_val)\n",
    "display(H_df)\n",
    "display(Q_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Distance Matrix ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.27710313 5.38938855 5.86808844 5.86809913 5.49054754 5.4905542 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.897297</td>\n",
       "      <td>0.377545</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.217979</td>\n",
       "      <td>0.377542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377545</td>\n",
       "      <td>5.897297</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.217979</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>5.897297</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.188765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.217979</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>5.897297</td>\n",
       "      <td>0.377545</td>\n",
       "      <td>0.217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.217979</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.377545</td>\n",
       "      <td>5.897297</td>\n",
       "      <td>0.377542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.188765</td>\n",
       "      <td>0.217972</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>5.897297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  5.897297  0.377545  0.217972  0.188775  0.217979  0.377542\n",
       "1  0.377545  5.897297  0.377542  0.217979  0.188775  0.217972\n",
       "2  0.217972  0.377542  5.897297  0.377542  0.217972  0.188765\n",
       "3  0.188775  0.217979  0.377542  5.897297  0.377545  0.217972\n",
       "4  0.217979  0.188775  0.217972  0.377545  5.897297  0.377542\n",
       "5  0.377542  0.217972  0.188765  0.217972  0.377542  5.897297"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.408250</td>\n",
       "      <td>0.408250</td>\n",
       "      <td>-0.50017</td>\n",
       "      <td>-0.288379</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.289045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408250</td>\n",
       "      <td>-0.408250</td>\n",
       "      <td>-0.49983</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>-0.500215</td>\n",
       "      <td>0.288301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408245</td>\n",
       "      <td>0.408245</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.577353</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.577352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408250</td>\n",
       "      <td>-0.408250</td>\n",
       "      <td>0.50017</td>\n",
       "      <td>0.288379</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.289045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408250</td>\n",
       "      <td>0.408250</td>\n",
       "      <td>0.49983</td>\n",
       "      <td>-0.288967</td>\n",
       "      <td>-0.500215</td>\n",
       "      <td>0.288301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.408245</td>\n",
       "      <td>-0.408245</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>-0.577353</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.577352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2         3         4         5\n",
       "0  0.408250  0.408250 -0.50017 -0.288379  0.499785  0.289045\n",
       "1  0.408250 -0.408250 -0.49983  0.288967 -0.500215  0.288301\n",
       "2  0.408245  0.408245  0.00034  0.577353  0.000430 -0.577352\n",
       "3  0.408250 -0.408250  0.50017  0.288379  0.499785  0.289045\n",
       "4  0.408250  0.408250  0.49983 -0.288967 -0.500215  0.288301\n",
       "5  0.408245 -0.408245 -0.00034 -0.577353  0.000430 -0.577352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coord = create_coord_array(benz_atom, 12)\n",
    "M_inv_dist = get_inv_dist_M(coord)\n",
    "Q_inv_dist_eig_val, Q_inv_dist = np.linalg.eig(M_inv_dist)\n",
    "np.savetxt('CCS_basis/Inverse_distance_basis.txt', Q_inv_dist)\n",
    "\n",
    "print(Q_inv_dist_eig_val)\n",
    "M_inv_dist_df = pd.DataFrame(M_inv_dist)\n",
    "Q_inv_dist_df = pd.DataFrame(Q_inv_dist)\n",
    "display(M_inv_dist_df)\n",
    "display(Q_inv_dist_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Projection Matrix ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299522</td>\n",
       "      <td>0.578496</td>\n",
       "      <td>-0.083805</td>\n",
       "      <td>-0.257781</td>\n",
       "      <td>0.687691</td>\n",
       "      <td>-0.170984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261689</td>\n",
       "      <td>-0.456619</td>\n",
       "      <td>0.085953</td>\n",
       "      <td>-0.061749</td>\n",
       "      <td>0.048034</td>\n",
       "      <td>-0.842324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260628</td>\n",
       "      <td>0.612509</td>\n",
       "      <td>-0.024358</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>-0.680893</td>\n",
       "      <td>-0.297220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481236</td>\n",
       "      <td>-0.170599</td>\n",
       "      <td>0.396131</td>\n",
       "      <td>-0.666556</td>\n",
       "      <td>-0.187974</td>\n",
       "      <td>0.320556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532336</td>\n",
       "      <td>-0.228489</td>\n",
       "      <td>-0.783564</td>\n",
       "      <td>0.088042</td>\n",
       "      <td>-0.052447</td>\n",
       "      <td>0.199843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.508831</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>0.462713</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  0.299522  0.578496 -0.083805 -0.257781  0.687691 -0.170984\n",
       "1  0.261689 -0.456619  0.085953 -0.061749  0.048034 -0.842324\n",
       "2  0.260628  0.612509 -0.024358  0.066004 -0.680893 -0.297220\n",
       "3  0.481236 -0.170599  0.396131 -0.666556 -0.187974  0.320556\n",
       "4  0.532336 -0.228489 -0.783564  0.088042 -0.052447  0.199843\n",
       "5  0.508831 -0.019035  0.462713  0.687990  0.151898  0.173844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a random symmetric positive definite matrix\n",
    "\n",
    "M_rand = np.array([[1., 0.06029536, 0.44295679, 0.27515277, 0.29444547, 0.45542014],\n",
    "                   [0.06029536, 1., 0.04501127, 0.30063993, 0.44013144, 0.31636733],\n",
    "                   [0.44295679, 0.04501127, 1., 0.26095881, 0.24953525, 0.32341057],\n",
    "                   [0.27515277, 0.30063993, 0.26095881, 1., 0.89543119, 0.67206881],\n",
    "                   [0.29444547, 0.44013144, 0.24953525, 0.89543119, 1., 0.90339149],\n",
    "                   [0.45542014, 0.31636733, 0.32341057, 0.67206881, 0.90339149, 1.]])\n",
    "Q_rand_eig_val, Q_rand = np.linalg.eig(M_rand)\n",
    "np.savetxt('CCS_basis/Random_matrix_basis.txt', Q_rand)\n",
    "\n",
    "Q_rand_df = pd.DataFrame(Q_rand)\n",
    "display(Q_rand_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda_c_square(c_arr, eig_val_arr):\n",
    "    \"\"\" \n",
    "    square each coefficient and multiply it by the ANM eigenvalue\n",
    "\n",
    "    Args:\n",
    "        c_arr (list): a list of the ANM coefficients\n",
    "        eig_val_arr (list): a list of the ANM eigenvalues\n",
    "    Returns:\n",
    "        list: the transformed coefficient\n",
    "    \"\"\"\n",
    "    transformed_c = [eig_val * coef**2 for eig_val, coef in zip(eig_val_arr, c_arr)]\n",
    "    return transformed_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dx', 'sorted_dx', 'lexi_dx', 'num_dope']\n",
      "['c', 'c_inv', 'sorted_c', 'lexi_c', 'lexi_c_inv', 'coulomb_sort_c']\n",
      "\n",
      "Sample c vector: [-0.35, -0.47, -1.11, -0.47, -0.35, 0.3]\n",
      "Sample lexi_c vector: [0.91, -0.09, 0.49, -0.09, 0.91, 0.32]\n",
      "Sample c_inv vector: [0.0, -0.12, 1.0, -0.0, -0.0, 0.99]\n",
      "Sample lexi_c_inv vector: [0.0, -0.64, -0.5, -0.87, -0.5, -0.58]\n",
      "\n",
      "Sample c_square_eig vector: [-0.32, -0.79, -4.38, -0.77, -0.43, -0.31]\n",
      "Sample lexi_c_square_eig vector: [-2.15, -0.03, -0.86, -0.03, -2.88, -0.36]\n",
      "Sample c_inv_square_eig vector: [-0.0, -0.05, -3.56, -0.0, -0.0, -3.46]\n",
      "Sample lexi_c_inv_square_eig vector: [-0.0, -1.48, -0.89, -2.63, -0.88, -1.19]\n"
     ]
    }
   ],
   "source": [
    "benzene_data_ANM_basis, dx_col, c_col = generate_coef_with_specific_basis(benzene_energy_data, Q, coord, ref_charge=6)\n",
    "print(dx_col)\n",
    "print(c_col)\n",
    "print()\n",
    "print(\"Sample c vector:\", [round(element, 2) for element in benzene_data_ANM_basis['c'][0]])\n",
    "print(\"Sample lexi_c vector:\", [round(element, 2) for element in benzene_data_ANM_basis['lexi_c'][0]])\n",
    "print(\"Sample c_inv vector:\", [round(element, 2) for element in benzene_data_ANM_basis['c_inv'][0]])\n",
    "print(\"Sample lexi_c_inv vector:\", [round(element, 2) for element in benzene_data_ANM_basis['lexi_c_inv'][0]])\n",
    "\n",
    "# engineer some new features\n",
    "# transformation: lambda * c^2\n",
    "\n",
    "benzene_data_ANM_basis['c_square_eig'] = benzene_data_ANM_basis['c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_eig_val))\n",
    "benzene_data_ANM_basis['lexi_c_square_eig'] = benzene_data_ANM_basis['lexi_c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_eig_val))\n",
    "benzene_data_ANM_basis['c_inv_square_eig'] = benzene_data_ANM_basis['c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_eig_val))\n",
    "benzene_data_ANM_basis['lexi_c_inv_square_eig'] = benzene_data_ANM_basis['lexi_c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_eig_val))\n",
    "print()\n",
    "print(\"Sample c_square_eig vector:\", [round(element, 2) for element in benzene_data_ANM_basis['c_square_eig'][0]])\n",
    "print(\"Sample lexi_c_square_eig vector:\", [round(element, 2) for element in benzene_data_ANM_basis['lexi_c_square_eig'][0]])\n",
    "print(\"Sample c_inv_square_eig vector:\", [round(element, 2) for element in benzene_data_ANM_basis['c_inv_square_eig'][0]])\n",
    "print(\"Sample lexi_c_inv_square_eig vector:\", [round(element, 2) for element in benzene_data_ANM_basis['lexi_c_inv_square_eig'][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "benzene_data_inv_dist_basis, dx_col, c_col = generate_coef_with_specific_basis(benzene_energy_data, Q_inv_dist, coord, ref_charge=6)\n",
    "benzene_data_inv_dist_basis['c_square_eig'] = benzene_data_inv_dist_basis['c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_inv_dist_eig_val))\n",
    "benzene_data_inv_dist_basis['lexi_c_square_eig'] = benzene_data_inv_dist_basis['lexi_c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_inv_dist_eig_val))\n",
    "benzene_data_inv_dist_basis['c_inv_square_eig'] = benzene_data_inv_dist_basis['c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_inv_dist_eig_val))\n",
    "benzene_data_inv_dist_basis['lexi_c_inv_square_eig'] = benzene_data_inv_dist_basis['lexi_c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_inv_dist_eig_val))\n",
    "\n",
    "benzene_data_rand_basis, dx_col, c_col = generate_coef_with_specific_basis(benzene_energy_data, Q_rand, coord, ref_charge=6)\n",
    "benzene_data_rand_basis['c_square_eig'] = benzene_data_rand_basis['c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_rand_eig_val))\n",
    "benzene_data_rand_basis['lexi_c_square_eig'] = benzene_data_rand_basis['lexi_c'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_rand_eig_val))\n",
    "benzene_data_rand_basis['c_inv_square_eig'] = benzene_data_rand_basis['c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_rand_eig_val))\n",
    "benzene_data_rand_basis['lexi_c_inv_square_eig'] = benzene_data_rand_basis['lexi_c_inv'].apply(lambda c_arr: compute_lambda_c_square(c_arr, Q_rand_eig_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Training Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANM_basis_datasets = generate_input_training_data(benzene_data_ANM_basis)\n",
    "inv_dist_basis_datasets = generate_input_training_data(benzene_data_inv_dist_basis)\n",
    "rand_basis_datasets = generate_input_training_data(benzene_data_rand_basis)\n",
    "\n",
    "complete_dataset = [ANM_basis_datasets, inv_dist_basis_datasets, rand_basis_datasets]\n",
    "prefixes = ['ANM', 'inv_dist', 'rand']\n",
    "dataset_names = ['X', 'X_inv', 'X_sorted', 'X_lexi', 'X_lexi_inv', 'X_nd', 'X_lexi_nd', 'X_coulomb',\n",
    "                     'X_square_eig', 'X_inv_square_eig', 'X_lexi_square_eig', 'X_lexi_inv_square_eig']\n",
    "\n",
    "dest_folder = \"../data/benzene_training_data\"\n",
    "for datasets, prefix in zip(complete_dataset, prefixes):\n",
    "    export_to_csv_custom(datasets, dataset_names, prefix, dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "\n",
    "y_energy, y_elec, y_delta_energy, y_delta_elec = generate_target_training_data(benzene_energy_data)\n",
    "\n",
    "y_energy.to_csv('../data/benzene_training_data/[Benz] y_energy.csv', index=False)\n",
    "y_elec.to_csv('../data/benzene_training_data/[Benz] y_elec.csv', index=False)\n",
    "y_delta_energy.to_csv('../data/benzene_training_data/[Benz] y_delta_energy.csv', index=False)\n",
    "y_delta_elec.to_csv('../data/benzene_training_data/[Benz] y_delta_elec.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': 3.4835443037974683e-13, 'coef0': 0.0024369823529411766, 'degree': 2, 'kernel': 'poly'}\n",
    "KRR_model = KernelRidge(**params)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    mse_scores = cross_val_score(KRR_model, X_concat, y_delta_energy, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    rmse_scores = np.sqrt(-mse_scores)  \n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_rmse = rmse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "print(\"Polynomial KRR:\")\n",
    "for fold, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {fold+1}: RMSE = {rmse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average RMSE across all folds: {avg_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernel ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': 1.5306122448979593e-09, 'gamma': 2.2857142857142856e-06, 'kernel': 'rbf'}\n",
    "KRR_model = KernelRidge(**params)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "mse_scores = cross_val_score(KRR_model, X_coulomb, y_delta_energy, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_rmse = rmse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "print(\"Polynomial KRR:\")\n",
    "for fold, rmse in enumerate(rmse_scores):\n",
    "    print(f\"Fold {fold+1}: RMSE = {rmse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average MSE across all folds: {avg_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Ridge Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liear_model = Ridge(alpha=1)\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(liear_model, X_lexi_nd, y_delta_energy, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "rmse_scores = np.sqrt(-mse_scores)  # Convert negative MSE scores to positive\n",
    "\n",
    "# Calculate the average error across all folds\n",
    "avg_rmse = rmse_scores.mean()\n",
    "\n",
    "# Print the mean squared error for each fold\n",
    "for fold, mse in enumerate(mse_scores):\n",
    "    print(f\"Fold {fold+1}: RMSE = {rmse}\")\n",
    "\n",
    "# Print the average mean squared error\n",
    "print(f\"Average MSE across all folds: {avg_rmse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Learning Curve ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(model, X, y, num_training_sample, num_trials):\n",
    "\n",
    "    \"\"\" \n",
    "    Given the number of training samples used, \n",
    "    calculate the average and standard deviation of MSE across a certain number of trials.\n",
    "    For each trial, a specified number of training examples is used to train the model, \n",
    "    which is then evaluated on the rest of the data set.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): training data; size (N, m) where N is the number of training examples and m is the number of features\n",
    "        y (ndarray): target data; size (N, 1)\n",
    "        num_training_sample (int): the number of samples used for training\n",
    "        num_trials: the number of trials \n",
    "    \n",
    "    Returns:\n",
    "        average_error: the average MSE across all trials\n",
    "        std_dev_error: standard deviation of the error across all trials\n",
    "    \"\"\"\n",
    "\n",
    "    errors = []\n",
    "    test_size = 1.0 - num_training_sample/X.shape[0]\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        error = mean_absolute_error(y_val, y_pred) \n",
    "        errors.append(error)\n",
    "    \n",
    "    average_error = np.mean(errors)\n",
    "    std_dev_error = np.std(errors)/np.sqrt(num_trials)\n",
    "    return average_error, std_dev_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly_lexi ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_lexi_delta_tot\n",
    "\n",
    "best_params = {'alpha': 3.4835443037974683e-13, 'coef0': 0.0024369823529411766, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_lexi_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_lexi_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_lexi_delta_tot, X_lexi, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_poly_lexi_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_lexi_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_lexi_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_lexi_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_lexi_delta_elec\n",
    "\n",
    "best_params = {'alpha': 3.4835443037974683e-13, 'coef0': 0.0024369823529411766, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_lexi_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_lexi_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_lexi_delta_elec, X_lexi, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_poly_lexi_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_lexi_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_lexi_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_lexi_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly_lexi_nd ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_lexi_nd_delta_tot\n",
    "\n",
    "best_params = {'alpha': 1e-13, 'coef0': 6.04e-06, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_lexi_nd_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_lexi_nd_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_lexi_nd_delta_tot, X_lexi_nd, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_poly_lexi_nd_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_lexi_nd_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_lexi_nd_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_lexi_nd_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_lexi_nd_delta_elec\n",
    "\n",
    "best_params = {'alpha': 1e-13, 'coef0': 6.04e-06, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_lexi_nd_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_lexi_nd_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_lexi_nd_delta_elec, X_lexi_nd, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_poly_lexi_nd_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_lexi_nd_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_lexi_nd_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_lexi_nd_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly_sorted ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_sorted_delta_tot\n",
    "\n",
    "best_params = {'alpha': 7.969230769230769e-13, 'coef0': 3.9076923076923075e-05, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_sorted_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_sorted_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_sorted_delta_tot, X_sorted, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_poly_sorted_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_sorted_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_sorted_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_sorted_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_sorted_delta_elec\n",
    "\n",
    "best_params = {'alpha': 7.969230769230769e-13, 'coef0': 3.9076923076923075e-05, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_sorted_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_sorted_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_sorted_delta_elec, X_sorted, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_poly_sorted_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_sorted_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_sorted_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_sorted_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly_coulomb ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_coulomb_delta_tot\n",
    "\n",
    "best_params = {'alpha': 0.1489795918367347, 'coef0': 1.183673469387755, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_coulomb_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_coulomb_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_coulomb_delta_tot, X_coulomb, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_poly_coulomb_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_coulomb_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_coulomb_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_coulomb_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly_coulomb_delta_elec\n",
    "\n",
    "best_params = {'alpha': 0.1489795918367347, 'coef0': 1.183673469387755, 'degree': 2, 'kernel': 'poly'}\n",
    "model_poly_coulomb_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_poly_coulomb_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_poly_coulomb_delta_elec, X_coulomb, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_poly_coulomb_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_poly_coulomb_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_poly_coulomb_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_poly_coulomb_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernel ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian_lexi ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_lexi_delta_tot\n",
    "\n",
    "best_params = {'alpha': 1e-17, 'gamma': 2e-07, 'kernel': 'rbf'}\n",
    "model_gaussian_lexi_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_lexi_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_lexi_delta_tot, X_lexi, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_lexi_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_lexi_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_lexi_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_lexi_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_lexi_delta_elec\n",
    "\n",
    "best_params = {'alpha': 1e-17, 'gamma': 2e-07, 'kernel': 'rbf'}\n",
    "model_gaussian_lexi_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_lexi_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_lexi_delta_elec, X_lexi, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_lexi_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_lexi_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_lexi_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_lexi_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian_lexi_nd ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_lexi_nd_delta_tot\n",
    "\n",
    "best_params = {'alpha': 3.755102040816326e-08, 'gamma': 1.7346938775510206e-06, 'kernel': 'rbf'}\n",
    "model_gaussian_lexi_nd_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_lexi_nd_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_lexi_nd_delta_tot, X_lexi_nd, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_lexi_nd_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_lexi_nd_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_lexi_nd_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_lexi_nd_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_lexi_nd_delta_elec\n",
    "\n",
    "best_params = {'alpha': 3.755102040816326e-08, 'gamma': 1.7346938775510206e-06, 'kernel': 'rbf'}\n",
    "model_gaussian_lexi_nd_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_lexi_nd_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_lexi_nd_delta_elec, X_lexi_nd, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_lexi_nd_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_lexi_nd_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_lexi_nd_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_lexi_nd_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian_sorted ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_sorted_delta_tot\n",
    "\n",
    "best_params = {'alpha': 1.5306122448979593e-9, 'gamma': 2.2857142857142856e-06, 'kernel': 'rbf'}\n",
    "model_gaussian_sorted_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_sorted_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_sorted_delta_tot, X_sorted, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_sorted_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_sorted_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_sorted_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_sorted_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_sorted_delta_elec\n",
    "\n",
    "best_params = {'alpha': 1.5306122448979593e-9, 'gamma': 2.2857142857142856e-06, 'kernel': 'rbf'}\n",
    "model_gaussian_sorted_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_sorted_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_sorted_delta_elec, X_sorted, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_sorted_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_sorted_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_sorted_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_sorted_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian coulomb ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_coulomb_delta_tot\n",
    "\n",
    "best_params = {'alpha': 1e-9, 'gamma': 1.5998587196060572e-05, 'kernel': 'rbf'}\n",
    "model_gaussian_coulomb_delta_tot = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_coulomb_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_coulomb_delta_tot, X_coulomb, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_coulomb_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_coulomb_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_coulomb_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_coulomb_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian_coulomb_delta_elec\n",
    "\n",
    "best_params = {'alpha': 1e-05, 'gamma': 1.5998587196060572e-05, 'kernel': 'rbf'}\n",
    "model_gaussian_coulomb_delta_elec = KernelRidge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_gaussian_coulomb_delta_elec = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_gaussian_coulomb_delta_elec, X_coulomb, y_delta_elec, num_training_sample, num_trials)\n",
    "        model_performance_gaussian_coulomb_delta_elec.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_gaussian_coulomb_delta_elec.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_gaussian_coulomb_delta_elec.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_gaussian_coulomb_delta_elec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_lexi_delta_tot\n",
    "\n",
    "best_params = {'alpha': 219}\n",
    "model_linear_lexi_delta_tot = Ridge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_linear_lexi_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_linear_lexi_delta_tot, X_lexi, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_linear_lexi_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_linear_lexi_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_linear_lexi_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_linear_lexi_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_lexi_nd_delta_tot\n",
    "\n",
    "best_params = {'alpha': 0.0367}\n",
    "model_linear_lexi_nd_delta_tot = Ridge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_linear_lexi_nd_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_linear_lexi_nd_delta_tot, X_lexi_nd, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_linear_lexi_nd_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_linear_lexi_nd_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_linear_lexi_nd_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_linear_lexi_nd_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_sorted_delta_tot\n",
    "\n",
    "best_params = {'alpha': 0.002}\n",
    "model_linear_sorted_delta_tot = Ridge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_linear_sorted_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_linear_sorted_delta_tot, X_sorted, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_linear_sorted_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_linear_sorted_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_linear_sorted_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_linear_sorted_delta_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_coulomb_delta_tot\n",
    "\n",
    "best_params = {'alpha': 5}\n",
    "model_linear_coulomb_delta_tot = Ridge(**best_params)\n",
    "\n",
    "columns = ['training size', 'average MAE (mHa)', 'standard deviation (mHa)']\n",
    "model_performance_linear_coulomb_delta_tot = pd.DataFrame(columns=columns)\n",
    "\n",
    "training_size = [2**i for i in range(1, 5)]\n",
    "num_trials = 20\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    for index, num_training_sample in enumerate(training_size):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        index = index + 1\n",
    "        average_error, std_dev_error = evaluate_performance(model_linear_coulomb_delta_tot, X_coulomb, y_delta_energy, num_training_sample, num_trials)\n",
    "        model_performance_linear_coulomb_delta_tot.at[index, 'training size'] = num_training_sample\n",
    "        model_performance_linear_coulomb_delta_tot.at[index, 'average MAE (mHa)'] = average_error * 1000\n",
    "        model_performance_linear_coulomb_delta_tot.at[index, 'standard deviation (mHa)'] = std_dev_error * 1000\n",
    "\n",
    "display(model_performance_linear_coulomb_delta_tot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_lexi_delta_tot['training size']\n",
    "\n",
    "y1 = model_performance_poly_lexi_delta_tot['average MAE (mHa)']\n",
    "y2 = model_performance_poly_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y3 = model_performance_poly_sorted_delta_tot['average MAE (mHa)']\n",
    "y4 = model_performance_poly_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "y5 = model_performance_gaussian_lexi_delta_tot['average MAE (mHa)']\n",
    "y6 = model_performance_gaussian_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y7 = model_performance_gaussian_sorted_delta_tot['average MAE (mHa)']\n",
    "y8 = model_performance_gaussian_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "y9 = model_performance_linear_lexi_delta_tot['average MAE (mHa)']\n",
    "y10 = model_performance_linear_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y11 = model_performance_linear_sorted_delta_tot['average MAE (mHa)']\n",
    "y12 = model_performance_linear_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "# Plotting\n",
    "linewidth = 4\n",
    "plt.plot(x, y1, label='Polynomial KRR (lexi)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y2, label='Polynomial KRR (lexi, num_doped)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y3, label='Polynomial KRR (sorted)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y4, label='Polynomial KRR (coulomb)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "plt.plot(x, y5, label='Gaussian KRR (lexi)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y6, label='Gaussian KRR (lexi, num_doped)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y7, label='Gaussian KRR (sorted)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y8, label='Gaussian KRR (coulomb)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "plt.plot(x, y9, label='Linear Model (lexi)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y10, label='Linear Model (lexi, num_doped)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y11, label='Linear Model (sorted)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y12, label='Linear Model (coulomb)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule total energy prediction')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Average MAE [mHa]')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "xticks = [2**i for i in range(1, 5)]\n",
    "yticks = [10**i for i in range(1, 4)]\n",
    "plt.xticks(xticks, labels = xticks)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] [2.0] [all] Learning curve for BN-Doped Benzene molecule total energy prediction.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_lexi_delta_tot['training size']\n",
    "\n",
    "y1 = model_performance_poly_lexi_delta_tot['average MAE (mHa)']\n",
    "y2 = model_performance_poly_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y3 = model_performance_poly_sorted_delta_tot['average MAE (mHa)']\n",
    "y4 = model_performance_poly_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "# Plotting\n",
    "linewidth = 4\n",
    "plt.plot(x, y1, label='Polynomial KRR (lexi)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y2, label='Polynomial KRR (lexi, num_doped)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y3, label='Polynomial KRR (sorted)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y4, label='Polynomial KRR (coulomb)', marker='o', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule total energy prediction')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Average MAE [mHa]')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "xticks = [2**i for i in range(1, 5)]\n",
    "yticks = [10**i for i in range(1, 4)]\n",
    "plt.xticks(xticks, labels = xticks)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] [2.0] [Poly] Learning curve for BN-Doped Benzene molecule total energy prediction.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_lexi_delta_tot['training size']\n",
    "\n",
    "y5 = model_performance_gaussian_lexi_delta_tot['average MAE (mHa)']\n",
    "y6 = model_performance_gaussian_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y7 = model_performance_gaussian_sorted_delta_tot['average MAE (mHa)']\n",
    "y8 = model_performance_gaussian_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "# Plotting\n",
    "linewidth = 4\n",
    "\n",
    "plt.plot(x, y5, label='Gaussian KRR (lexi)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y6, label='Gaussian KRR (lexi, num_doped)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y7, label='Gaussian KRR (sorted)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y8, label='Gaussian KRR (coulomb)', marker='^', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule total energy prediction')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Average MAE [mHa]')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "xticks = [2**i for i in range(1, 5)]\n",
    "yticks = [10**i for i in range(1, 4)]\n",
    "plt.xticks(xticks, labels = xticks)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] [2.0] [Gaussian] Learning curve for BN-Doped Benzene molecule total energy prediction.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_lexi_delta_tot['training size']\n",
    "\n",
    "y9 = model_performance_linear_lexi_delta_tot['average MAE (mHa)']\n",
    "y10 = model_performance_linear_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y11 = model_performance_linear_sorted_delta_tot['average MAE (mHa)']\n",
    "y12 = model_performance_linear_coulomb_delta_tot['average MAE (mHa)']\n",
    "\n",
    "# Plotting\n",
    "linewidth = 4\n",
    "\n",
    "plt.plot(x, y9, label='Linear Model (lexi)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y10, label='Linear Model (lexi, num_doped)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y11, label='Linear Model (sorted)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "plt.plot(x, y12, label='Linear Model (coulomb)', marker='*', linestyle='-', linewidth=linewidth)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule total energy prediction')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Average MAE [mHa]')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "xticks = [2**i for i in range(1, 5)]\n",
    "yticks = [10**i for i in range(1, 4)]\n",
    "plt.xticks(xticks, labels = xticks)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] [2.0] [Linear] Learning curve for BN-Doped Benzene molecule total energy prediction.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Performing\n",
    "\n",
    "# No error bar\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Load the data\n",
    "x = model_performance_poly_lexi_delta_tot['training size']\n",
    "\n",
    "y6 = model_performance_gaussian_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y7 = model_performance_gaussian_sorted_delta_tot['average MAE (mHa)']\n",
    "\n",
    "y10 = model_performance_linear_lexi_nd_delta_tot['average MAE (mHa)']\n",
    "y11 = model_performance_linear_sorted_delta_tot['average MAE (mHa)']\n",
    "\n",
    "# Plotting\n",
    "linewidth = 4\n",
    "markersize = 20\n",
    "\n",
    "plt.plot(x, y6, label='Gaussian KRR (lexi, num_doped)', marker='^', linestyle='-', linewidth=linewidth, markersize=markersize)\n",
    "plt.plot(x, y7, label='Gaussian KRR (sorted)', marker='^', linestyle='-', linewidth=linewidth, markersize=markersize)\n",
    "\n",
    "plt.plot(x, y10, label='Linear Model (lexi, num_doped)', marker='*', linestyle='--', linewidth=linewidth, markersize=markersize)\n",
    "plt.plot(x, y11, label='Linear Model (sorted)', marker='*', linestyle='--', linewidth=linewidth, markersize=markersize)\n",
    "\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Learning curve for BN-Doped Benzene molecule total energy prediction')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Average MAE [mHa]')\n",
    "plt.legend()\n",
    "\n",
    "# Create log scale\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "xticks = [2**i for i in range(1, 5)]\n",
    "yticks = [10**i for i in range(1, 4)]\n",
    "plt.xticks(xticks, labels = xticks)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('../Graph/[Benz] [2.0] [best] Learning curve for BN-Doped Benzene molecule total energy prediction.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With Error Bar\n",
    "# # Set figure size\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Load the data\n",
    "# x = model_performance_poly_KRR['training size']\n",
    "# y1 = model_performance_poly_KRR['average RMSE']\n",
    "# y2 = model_performance_gaussian_KRR['average RMSE']\n",
    "# y3 = model_performance_ridge_regression['average RMSE']\n",
    "# y1_error = model_performance_poly_KRR['standard deviation']\n",
    "# y2_error = model_performance_gaussian_KRR['standard deviation']\n",
    "# y3_error = model_performance_ridge_regression['standard deviation']\n",
    "\n",
    "# # Plotting\n",
    "# # plt.plot(x, y1, label='Polynomial KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "# # plt.plot(x, y2, label='Gaussian KRR', marker='o', linestyle='-', linewidth=2.5)\n",
    "# # plt.plot(x, y3, label='Ridge Regression', marker='o', linestyle='-', linewidth=2.5)\n",
    "# plt.errorbar(x, y1, label='Polynomial KRR', yerr=y1_error, marker='o', linestyle='-', capsize=3)\n",
    "# plt.errorbar(x, y2, label='Gaussian KRR', yerr=y2_error, marker='o', linestyle='-', capsize=3)\n",
    "# plt.errorbar(x, y3, label='Ridge Regression', yerr=y3_error, marker='o', linestyle='-', capsize=3)\n",
    "\n",
    "# # Customize the plot\n",
    "# plt.title('Learning curve for BN-Doped Benzene molecule energy prediction')\n",
    "# plt.xlabel('Training Size (log)')\n",
    "# plt.ylabel('Average RMSE [Ha] (log)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Create log scale\n",
    "# plt.xscale('log', base=2)\n",
    "# plt.yscale('log', base=2)\n",
    "\n",
    "# # yticks = [2**i for i in range(-4, 7)]\n",
    "# yticks = [2**i for i in range(0, 7)]\n",
    "# plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "# # Display the plot\n",
    "# plt.savefig('../Graph/[Benz] learning_curve_16_points_with_err_bar.png', dpi=300)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to Prediction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that contains the energies predicted by the model and the actual energy\n",
    "\n",
    "# Specifies the columns of the dataframe and create an empty dataframe\n",
    "columns = ['Elements', 'Poly KRR prediction', 'Gaussian KRR prediction', 'Ridge regression prediction', 'Actual energy']\n",
    "model_prediction = pd.DataFrame(columns=columns)\n",
    "\n",
    "# fill in elements and the actual energy values from the original benzene_data dataframe\n",
    "model_prediction['Elements'] = benzene_data['Elements']\n",
    "model_prediction['Actual energy'] = benzene_data['Energy']\n",
    "\n",
    "# fit the gaussian KRR and ridge regression model on the training set\n",
    "gaussian_KRR_model.fit(X, y)\n",
    "ridge_model.fit(X, y)\n",
    "poly_KRR_model.fit(X, y)\n",
    "\n",
    "# iterate through each row entry of the data\n",
    "for index, row in model_prediction.iterrows():\n",
    "    x_pred = X.loc[[index]] # extract the input to be predicted\n",
    "    \n",
    "    # predict energy using the two models\n",
    "    # the given prediction is in a list of one element. use [0] to extract the actual value\n",
    "    gaussian_prediction = gaussian_KRR_model.predict(x_pred)[0] \n",
    "    ridge_prediction = ridge_model.predict(x_pred)[0]\n",
    "    poly_prediction = poly_KRR_model.predict(x_pred)[0] \n",
    "    \n",
    "    # Record the prediction in the DataFrame\n",
    "    model_prediction.at[index, 'Poly KRR prediction'] = poly_prediction\n",
    "    model_prediction.at[index, 'Gaussian KRR prediction'] = gaussian_prediction\n",
    "    model_prediction.at[index, 'Ridge regression prediction'] = ridge_prediction\n",
    "\n",
    "# display the data\n",
    "display(model_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the results\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "x = [i for i in range(17)]\n",
    "y_pred_1 = model_prediction['Gaussian KRR prediction']\n",
    "y_pred_2 = model_prediction['Ridge regression prediction']\n",
    "y_pred_3 = model_prediction['Poly KRR prediction']\n",
    "y = model_prediction['Actual energy']\n",
    "\n",
    "plt.plot(x, y_pred_1, label='Gaussian KRR prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y_pred_2, label='Ridge regression prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y_pred_3, label='Poly KRR prediction', marker='o', linestyle='-', linewidth=2.5)\n",
    "plt.plot(x, y, label='Actual energy', marker='o', linestyle='-', linewidth=2.5)\n",
    "\n",
    "plt.title('Comparing model prediction with actual energy')\n",
    "plt.xlabel('Element index')\n",
    "plt.ylabel('Energy [Ha]')\n",
    "plt.legend()\n",
    "\n",
    "yticks = np.linspace(-230, -240, num=11)\n",
    "plt.yticks(yticks, labels = yticks)\n",
    "\n",
    "plt.savefig('../Graph/[Benz] comparing_model_performance.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
