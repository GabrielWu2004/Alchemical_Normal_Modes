{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../../helper_code')\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import copy\n",
    "\n",
    "from helper_code.custom_kernel import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "input_dataset = ['c', 'c_lexi', 'CE', 'CE_lexi', 'CSE', 'CSE_lexi']\n",
    "dataset_dict = {}\n",
    "\n",
    "for data in input_dataset:\n",
    "    dataset_dict[data] = pd.read_csv(f'../data/benzene_training_data/[Benz]_{data}.csv')\n",
    "delta_delta_total_energy = pd.read_csv('../data/benzene_training_data/DD_e_tot (kcal).csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly_lexi_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small alpha, small coef0\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e-3), num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2, 3, 4], \n",
    "    'coef0': np.logspace(np.log10(1e-5), np.log10(1e-1), num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small alpha, large coef0\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e-3), num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2, 3, 4], \n",
    "    'coef0': np.logspace(np.log10(1e-1), np.log10(1e3), num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large alpha, small coef0\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-3), np.log10(1e1), num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2, 3, 4], \n",
    "    'coef0': np.logspace(np.log10(1e-5), np.log10(1e-1), num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large alpha, large coef0\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-3), np.log10(1e1), num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2, 3, 4], \n",
    "    'coef0': np.logspace(np.log10(1e-1), np.log10(1e3), num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-8, 1e-6, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-10, 1e-8, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-8, 1e-6, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-10, 1e-8, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-8, 1e-6, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-8, 1e-6, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-12, 1e-10, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-8, 1e-4, num=80), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-14, 1e-12, num=80),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-8, 1e-2, num=120), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-13, 1e-12, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.001, 0.01, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(2e-13, 5e-13, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.001, 0.01, num=100), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(3e-13, 4e-13, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.002, 0.003, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly_lexi_nd_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e-3), num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2, 3, 4], \n",
    "    'coef0': np.logspace(np.log10(1e-5), np.log10(1e-1), num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-9, 1e-7, num=51, endpoint=True),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-7, 1e-5, num=51, endpoint=True), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-11, 1e-9, num=51, endpoint=True),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 2e-6, num=51, endpoint=True), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-13, 1e-11, num=51, endpoint=True),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-7, 1e-5, num=51, endpoint=True), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-15, 1e-13, num=51, endpoint=True),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-7, 1e-5, num=51, endpoint=True), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-17, 1e-15, num=51, endpoint=True),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-5, num=51, endpoint=True), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly_sorted_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-8, 1e-6, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-10, 1e-8, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-12, 1e-10, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-14, 1e-12, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1e-6, 1e-4, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(6e-13, 9e-13, num=40),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(3e-5, 5e-5, num=40), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly_coulomb_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e-3), num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.logspace(np.log10(1e-5), np.log10(1e-1), num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(0.001, 0.1, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.001, 0.01, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(0.1, 1, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.01, 0.1, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(0.1, 0.2, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(0.1, 1, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(0.1, 0.2, num=50),\n",
    "    'kernel': ['poly'],  \n",
    "    'degree': [2], \n",
    "    'coef0': np.linspace(1, 10, num=50), \n",
    "}\n",
    "\n",
    "poly_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(poly_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Kernel ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian_lexi_delta_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-15, 1e-13, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-7, 1e-5, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-17, 1e-15, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(2e-7, 4e-7, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian_lexi_nd_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small alpha, small gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-9), np.log10(1e-5), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(1e-7), np.log10(1e-3), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-9, 1e-7, num=51, endpoint=True),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-7, 1e-5, num=51, endpoint=True),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-8, 1e-7, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-6, 5e-6, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian_sorted_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small alpha, small gamma\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-9), np.log10(1e-5), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(1e-7), np.log10(1e-3), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.1332767624303391\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-5, 1e-3, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-6, 1e-4, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-07, 'gamma': 0.0008787755102040817, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.13327457653034555\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-7, 1e-5, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-5, 1e-3, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-15, 'gamma': 0.0007306122448979592, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.12216791615977746\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-15, 1e-13, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(0.0006, 0.001, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 5.555102040816327e-16, 'gamma': 0.003579591836734694, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.11916077001687622\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-17, 1e-15, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(0.0007, 0.009, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3.4081632653061223e-16, 'gamma': 0.0028367346938775514, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.11787818055224993\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(3e-16, 7e-16, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(0.001, 0.006, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3e-16, 'gamma': 0.0032346938775510204, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.1098240556228957\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(3e-16, 4e-16, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(0.0025, 0.0035, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 2e-16, 'gamma': 0.0032346938775510204, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.1098240556228957\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(2e-16, 3e-16, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': [0.0032346938775510204],  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_sorted, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian_coulombic_delta_tot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-9), np.log10(1e-5), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(1e-7), np.log10(1e-3), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-10, 1e-9, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(7e-5, 5e-5, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-10, 1e-9, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-7, 1e-5, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_coulomb, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear_lexi_nd_delta ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge()\n",
    "\n",
    "# Define the hyperparameters to tune and their respective values\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e2), num=360),  # Regularization strength\n",
    "}\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(linear_model, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge()\n",
    "\n",
    "# Define the hyperparameters to tune and their respective values\n",
    "param_grid = {\n",
    "    'alpha': np.linspace(0.02, 0.05, num=100),  # Regularization strength\n",
    "}\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(linear_model, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_nd, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Gaussian Kernel ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def generate_parameter_combinations(param_grid):\n",
    "    \"\"\" \n",
    "    Generate all possible parameter combinations:\n",
    "    - Iterate over combinations of parameter values using 'product(*values)'\n",
    "    - For each combination, zip the parameter names ('keys') with the values\n",
    "      and create a dictionary using 'dict(zip(keys, combination))'\n",
    "    - Collect all dictionaries in a list comprehension\n",
    "\n",
    "    Parameters:\n",
    "        param_grid (dict): Dictionary of parameters and their possible values.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries representing all possible parameter combinations.\n",
    "    \"\"\"\n",
    "\n",
    "    keys = param_grid.keys()     # type is dict_keys\n",
    "    values = param_grid.values() # type is dict_values\n",
    "    return [dict(zip(keys, combination)) for combination in product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4],\n",
    "    'epsilon': [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1], \n",
    "    'beta': [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1], \n",
    "    'alpha': [1e-9, 5e-9, 1e-8, 5e-8, 1e-7, 5e-7, 1e-6] \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.linspace(1e-10, 1e-9, num=10),\n",
    "    'epsilon': np.linspace(4e-4, 6e-4, num=10), \n",
    "    'beta': np.linspace(1e-7, 5e-7, num=10),\n",
    "    'alpha': [1e-15]\n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_param = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_param = param_copy\n",
    "\n",
    "print(best_param)\n",
    "print(best_mean_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient Sequared Eig ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Gaussian ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-08, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.024065022940014474\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-8, 1e-3, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-8, 1e-3, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1e-13, 'gamma': 1.7575106248547965e-11, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.023539081477048356\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-13), np.log10(1e-8), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(1e-13), np.log10(1e-8), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3.5564803062231213e-16, 'gamma': 3.3932217718953296e-12, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.02167388059908677\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.logspace(np.log10(1e-18), np.log10(1e-13), num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.logspace(np.log10(1e-12), np.log10(1e-10), num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3.387755102040816e-16, 'gamma': 1.7346938775510203e-12, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.02080583000859528\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(1e-16, 1e-15, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-12, 1e-11, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3.346938775510204e-16, 'gamma': 2.7142857142857142e-12, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.020633122042542803\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(3e-16, 4e-16, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(1e-12, 5e-12, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 3.346938775510204e-16, 'gamma': 2.7142857142857142e-12, 'kernel': 'rbf'}\n",
      "Best Root Mean Squared Error: 0.020633122042542803\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha': np.linspace(3e-16, 4e-16, num=50),  # Regularization parameter controlling the L2 regularization term\n",
    "    'gamma': np.linspace(2e-12, 3e-12, num=50),  # Parameter for the Gaussian kernel, controlling the width of the kernel\n",
    "    'kernel': ['rbf'],  # Specifies the kernel function to be used, in this case, the Gaussian (RBF) kernel\n",
    "}\n",
    "\n",
    "gaussian_KRR = KernelRidge()\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grid_search = GridSearchCV(gaussian_KRR, param_grid, scoring='neg_mean_squared_error', cv=k_fold)\n",
    "    grid_search.fit(X_lexi_inv_square_eig, y_delta_energy)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = np.sqrt(-grid_search.best_score_)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Root Mean Squared Error:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Guassian ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 1e-07, 'epsilon': 0.001, 'beta': 0.1, 'alpha': 1e-06}\n",
      "Best score: 1.405021514056013\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4],\n",
    "    'epsilon': [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1], \n",
    "    'beta': [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1], \n",
    "    'alpha': [1e-9, 5e-9, 1e-8, 5e-8, 1e-7, 5e-7, 1e-6] \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 1e-07, 'epsilon': 1e-05, 'beta': 1e-05, 'alpha': 1e-07}\n",
      "Best score: 0.33782084262840406\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.logspace(np.log10(1e-9), np.log10(1e-7), num=7),\n",
    "    'epsilon': np.logspace(np.log10(1e-5), np.log10(1e-3), num=7), \n",
    "    'beta': np.logspace(np.log10(1e-5), np.log10(1e-3), num=7), \n",
    "    'alpha': np.logspace(np.log10(1e-8), np.log10(1e-6), num=7) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 1.7782794100389227e-07, 'epsilon': 1e-07, 'beta': 1.778279410038923e-06, 'alpha': 3.162277660168379e-07}\n",
      "Best score: 0.027820528560536635\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.logspace(np.log10(1e-8), np.log10(1e-6), num=9),\n",
    "    'epsilon': np.logspace(np.log10(1e-7), np.log10(1e-5), num=9), \n",
    "    'beta': np.logspace(np.log10(1e-7), np.log10(1e-5), num=9), \n",
    "    'alpha': np.logspace(np.log10(1e-8), np.log10(1e-6), num=9) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0e-07 1.5e-07 2.0e-07 2.5e-07 3.0e-07 3.5e-07 4.0e-07 4.5e-07 5.0e-07]\n",
      "[1.00000000e-07 1.22284454e-07 1.49534878e-07 1.82857910e-07\n",
      " 2.23606798e-07 2.73436353e-07 3.34370152e-07 4.08882717e-07\n",
      " 5.00000000e-07]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(1e-7, 5e-7, num=9, endpoint=True))\n",
    "print(np.logspace(np.log10(1e-7), np.log10(5e-7), num=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 1e-07, 'epsilon': 1e-09, 'beta': 2.2360679774997895e-06, 'alpha': 1e-07}\n",
      "Best score: 0.023318692621455295\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.logspace(np.log10(1e-7), np.log10(5e-7), num=9),\n",
    "    'epsilon': np.logspace(np.log10(1e-9), np.log10(1e-7), num=9), \n",
    "    'beta': np.logspace(np.log10(1e-6), np.log10(5e-6), num=9), \n",
    "    'alpha': np.logspace(np.log10(1e-7), np.log10(1e-6), num=9) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 4.999999999999999e-08, 'epsilon': 1e-11, 'beta': 2e-06, 'alpha': 7.498942093324559e-08}\n",
      "Best score: 0.022068364657641663\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.logspace(np.log10(5e-8), np.log10(1e-7), num=9),\n",
    "    'epsilon': np.logspace(np.log10(1e-11), np.log10(1e-9), num=9), \n",
    "    'beta': np.linspace(2e-6, 3e-6, num=9, endpoint=True), \n",
    "    'alpha': np.logspace(np.log10(1e-8), np.log10(1e-7), num=9) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 2.7343635285210528e-08, 'epsilon': 1e-13, 'beta': 1.125e-06, 'alpha': 4.999999999999999e-08}\n",
      "Best score: 0.021865089243977343\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.logspace(np.log10(1e-8), np.log10(5e-8), num=9),\n",
    "    'epsilon': np.logspace(np.log10(1e-13), np.log10(1e-11), num=9), \n",
    "    'beta': np.linspace(1e-6, 2e-6, num=9, endpoint=True), \n",
    "    'alpha': np.logspace(np.log10(5e-8), np.log10(1e-7), num=9) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 2.5e-08, 'epsilon': 1e-13, 'beta': 1e-06, 'alpha': 4.088827169789712e-08}\n",
      "Best score: 0.02183295823155789\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.linspace(2.5e-8, 3.5e-8, num=9, endpoint=True),\n",
    "    'epsilon': [0, 1e-19, 1e-17, 1e-15, 1e-13], \n",
    "    'beta': np.linspace(1e-6, 1.5e-6, num=9, endpoint=True), \n",
    "    'alpha': np.logspace(np.log10(1e-8), np.log10(5e-8), num=9) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 2.3749999999999998e-08, 'epsilon': 1e-13, 'beta': 1e-06, 'alpha': 4e-08}\n",
      "Best score: 0.021824137110720777\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.linspace(2e-8, 3e-8, num=9, endpoint=True),\n",
    "    'epsilon': np.logspace(np.log10(1e-14), np.log10(1e-13), num=9), \n",
    "    'beta': np.linspace(1e-6, 1.5e-6, num=9, endpoint=True), \n",
    "    'alpha': np.linspace(3e-8, 5e-8, num=9, endpoint=True) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 2.3e-08, 'epsilon': 4.999999999999999e-13, 'beta': 9.249999999999999e-07, 'alpha': 3.85e-08}\n",
      "Best score: 0.021812319989313496\n"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame and Series to numpy arrays\n",
    "X_train = X_lexi_inv_square_eig.to_numpy()\n",
    "y_train = y_delta_energy.to_numpy()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'gamma': np.linspace(2.3e-8, 2.5e-8, num=9, endpoint=True),\n",
    "    'epsilon': np.logspace(np.log10(5e-14), np.log10(5e-13), num=9), \n",
    "    'beta': np.linspace(9e-7, 1e-6, num=9, endpoint=True), \n",
    "    'alpha': np.linspace(3.8e-8, 4.2e-8, num=9, endpoint=True) \n",
    "}\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "parameter_combinations = generate_parameter_combinations(param_grid)\n",
    "best_mean_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "# Iterate through every parameter combination\n",
    "for params in parameter_combinations:\n",
    "    \n",
    "    # Make a copy of the parameters\n",
    "    param_copy = copy.deepcopy(params)\n",
    "\n",
    "    alpha = params.pop('alpha') # the params passed into the kernel doesn't include regularzation\n",
    "    similarity_matrix = create_similarity_matrix(X_train, X_train, extended_gaussian_kernel, params)\n",
    "    krr_model = KernelRidge(kernel='precomputed', alpha=alpha)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(krr_model, similarity_matrix, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    avg_rmse = rmse_scores.mean()\n",
    "\n",
    "    if avg_rmse < best_mean_score:\n",
    "        best_mean_score = avg_rmse\n",
    "        best_params = param_copy\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {best_mean_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
